---
title: "DEanalysis"
---

<https://hbctraining.github.io/Intro-to-DGE/schedule/links-to-lessons.html>

```{r}
#Pakete werden aus Setup Skript geladen
source("../../org/setup_packages.R")

suppressPackageStartupMessages(
{library(tidyverse)  
library(readxl)
library(janitor)
library(DESeq2)
library(tximport)
library(pheatmap)
library(RColorBrewer)
library(ggrepel)
library(cowplot)
library(DEGreport)
library(clusterProfiler)
library(DOSE)
library(org.Hs.eg.db)
library(pathview)
library(AnnotationHub)
library(ensembldb)
library(apeglm)
library(ashr)
})
sessionInfo()
```

```{r}
#| echo: false
#| warning: false
# Pfade
salmon <- "../../dat/salmon_files"
tx2g   <- "../../dat/info_files/tx2gene.tsv"
excel  <- "../../dat/info_files/CCGA_sequencing_NM_ventricular_dysfunction_RNAseq_2342.xlsx"

# Salmon-Files einlesen
files <- list.files(
  path      = salmon,
  full.names = TRUE,
  pattern   = "_quant\\.sf$"
)

# Saubere Namen f√ºr tximport
names(files) <- basename(files) %>%
  str_remove("_quant\\.sf$") %>%    # Endung entfernen
  str_remove("-L[0-9]+$")           # evtl. Library-Nummer entfernen

# Duplikate ausschlie√üen
stopifnot(length(files) > 1)
stopifnot(!anyDuplicated(names(files)))

# tx2gene einlesen
tx2gene <- read.delim(tx2g)
tx2gene[,1] <- sub("\\..*$", "", tx2gene[,1])  # Versionsnummer entfernen
tx2gene <- tx2gene[, c(1,2)]                    # Nur tx_id und gene_id

# tximport
txi_cache <- "../../res/cache/txi_salmon_tximport.rds"
dir.create(dirname(txi_cache), recursive = TRUE, showWarnings = FALSE)

if (file.exists(txi_cache)) {
  message("‚úÖ Lade tximport Cache: ", txi_cache)
  txi <- readRDS(txi_cache)
} else {
  message("‚è≥ Rechne tximport‚Ä¶")
  txi <- tximport(
    files,
    type = "salmon",
    tx2gene = tx2gene,
    countsFromAbundance = "lengthScaledTPM",
    ignoreTxVersion = TRUE
  )
  saveRDS(txi, txi_cache)
  message("üíæ Gespeichert: ", txi_cache)
}

# Sample-Namen in txi bereinigen
colnames(txi$counts)    <- str_remove(colnames(txi$counts), "_quant\\.sf$")
colnames(txi$abundance) <- str_remove(colnames(txi$abundance), "_quant\\.sf$")
colnames(txi$length)    <- str_remove(colnames(txi$length), "_quant\\.sf$")

# Metadata einlesen
md <- read_excel(excel, sheet = "Metadata", skip = 1) %>%
  janitor::clean_names() %>%
  mutate(sample_id = str_remove(library_id, "-L[0-9]+$") %>% str_trim())

input <- read_excel(excel, sheet = 3, skip = 1) %>%
  janitor::clean_names() %>%
  mutate(
    valve_treated = if_else(str_starts(sample_name, regex("^t", TRUE)),
                            "tricuspid valve",
                            "aortic valve"),
    timepoint = str_extract(sample_name, "(?<=_).*"),
    pid       = str_extract(sample_name, "^[^_]+")
  ) %>%
  dplyr::select(external_id, valve_treated, timepoint, pid)

md <- left_join(md, input, by = "external_id")
stopifnot(all(!is.na(md$valve_treated)))

# ============================================================
# Diagnostik: Counts-Samples vs. Metadata-Samples
# ============================================================
counts_samples <- colnames(txi$counts)

in_counts_not_meta <- setdiff(counts_samples, md$sample_id)
in_meta_not_counts <- setdiff(md$sample_id, counts_samples)

message("Samples in counts but not metadata: ", length(in_counts_not_meta))
message("Samples in metadata but not counts: ", length(in_meta_not_counts))

if (length(in_counts_not_meta) > 0) {
  message("‚Üí In counts, not in metadata:")
  print(in_counts_not_meta)
}

if (length(in_meta_not_counts) > 0) {
  message("‚Üí In metadata, not in counts:")
  print(in_meta_not_counts)
}

# Abbrechen, wenn es Mismatches gibt
stopifnot(length(in_counts_not_meta) == 0, length(in_meta_not_counts) == 0)


# Nur Aorten-Samples behalten
keep_aortic <- intersect(colnames(txi$counts),
                         md$sample_id[md$valve_treated == "aortic valve"])

stopifnot(length(keep_aortic) > 1)
stopifnot(!anyDuplicated(keep_aortic))

txi_aortic <- list(
  counts    = txi$counts[, keep_aortic, drop = FALSE],
  abundance = txi$abundance[, keep_aortic, drop = FALSE],
  length    = txi$length[, keep_aortic, drop = FALSE]
)


md_aortic <- md[md$sample_id %in% keep_aortic, ]

cat("Anzahl Aorten-Samples:", length(keep_aortic), "\n")
head(md_aortic)


```

```{r}
#| echo: false
#| warning: false

### Exploring RNA-seq count data

#Die Count-Verteilung einer einzelnen Probe ansehen
counts_aortic <- as.data.frame(txi_aortic$counts)

sample <- colnames(counts_aortic)[1]

ggplot(counts_aortic) +
  geom_histogram(aes(x = .data[[sample]]), bins = 200) +
  xlab("Raw expression counts") +
  ylab("Number of genes")

# Mean‚ÄìVariance Plot (RNA-seq count data) f√ºr Aorten-Counts

# 2) Mean und Varianz pro Gen (√ºber alle ausgew√§hlten Samples/Spalten)
mean_counts     <- apply(counts_aortic, 1, mean, na.rm = TRUE)  # '1' = zeilenweise (Gene)
variance_counts <- apply(counts_aortic, 1, var,  na.rm = TRUE)

# 3) Dataframe f√ºr ggplot
df_mv <- data.frame(
  mean_counts = mean_counts,
  variance_counts = variance_counts
)

# Gene mit mean/var <= 0 entfernen (log10 braucht > 0)
df_mv <- dplyr::filter(
  df_mv,
  mean_counts > 0,
  variance_counts > 0
)

# 4) Plot: log10-mean vs log10-variance, rote Linie = x=y
ggplot(df_mv) +
  geom_point(aes(x = mean_counts, y = variance_counts), alpha = 0.4) +
  scale_x_log10(limits = c(1, 1e9)) +
  scale_y_log10(limits = c(1, 1e9)) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(
    title = "Mean‚ÄìVariance Relationship (Aortic valve RNA-seq counts)",
    x = "Mean of counts per gene (log10)",
    y = "Variance of counts per gene (log10)"
  )
# Daten passen nicht zur Poission-Verteilung, weil die Varianz >> Mittelwert (Overdispersion). Besonders bei h√∂her exprimierten Genene ist die Varianz viel gr√∂√üer. Das rechtfertigt die Verwendung der Negativ-Binomial-Modelle von DESeq2

# ============================================================
# DESeq2: Normalisierung (Size-Factor / "median-of-ratios")
# Kontext: Salmon -> tximport -> DESeq2
# Ziel: Normalisierte Counts erzeugen (nur f√ºr Visualisierung/QC),
#       NICHT als Input f√ºr DE-Tests verwenden.
# ============================================================

# ------------------------------------------------------------
# VORAUSSETZUNGEN (existieren bereits im Workspace)
#   txi        : komplettes tximport-Objekt (aus tximport())
#   txi_aortic : gefiltertes tximport-Objekt f√ºr Aorten-Samples
#               (list mit counts/abundance/length)
#   md_aortic  : Metadata passend zu Aorten-Samples
#               (mind. sample_id, pid, timepoint)
# ------------------------------------------------------------

# ------------------------------------------------------------
# 1) Metadata f√ºr DESeq2 vorbereiten
#    - sample_id muss character sein (IDs)
#    - pid/timepoint als factor (Design-Variablen)
#    - rownames(meta) m√ºssen exakt die Sample-IDs sein
# ------------------------------------------------------------
meta <- md_aortic %>%
  mutate(
    sample_id = as.character(sample_id),
    pid       = factor(pid),        # Patient-ID
    timepoint = factor(timepoint)   
  ) %>%
  as.data.frame()

rownames(meta) <- meta$sample_id

# ------------------------------------------------------------
# 2) Sicherstellen, dass Counts-Spalten und Metadata-Zeilen matchen
#    DESeq2 verlangt:
#      colnames(counts) == rownames(colData)
#    Reihenfolge ist wichtig (sonst falsche Zuordnung)
# ------------------------------------------------------------

# Check: alle Count-Sample-IDs existieren in meta?
stopifnot(all(colnames(txi_aortic$counts) %in% rownames(meta)))

# Meta exakt in die Reihenfolge der Count-Spalten bringen
meta <- meta[match(colnames(txi_aortic$counts), rownames(meta)), , drop = FALSE]

# Check: jetzt exakt identisch und in gleicher Reihenfolge?
stopifnot(all(colnames(txi_aortic$counts) == rownames(meta)))

# ------------------------------------------------------------
# 3) tximport-Metainfo erhalten
#    DESeqDataSetFromTximport() erwartet u.a. txi$countsFromAbundance
#    Wenn txi_aortic manuell als Liste gebaut wurde, fehlt das
# ------------------------------------------------------------
txi_aortic$countsFromAbundance <- txi$countsFromAbundance

# ------------------------------------------------------------
# 4) DESeqDataSet erstellen
#    Design: ~ pid + timepoint
#    - pid modelliert patientenspezifische Baselines
#    - timepoint testet die systematische √Ñnderung √ºber die Zeit
# ------------------------------------------------------------
dds <- DESeqDataSetFromTximport(
  txi = txi_aortic,
  colData = meta,
  design = ~ pid + timepoint
)

# ------------------------------------------------------------
# 5) Prefiltering:
#    Entfernt Gene mit extrem niedrigen Counts in allen Samples,
#    verbessert Laufzeit und reduziert Noise.
# ------------------------------------------------------------
dds <- dds[rowSums(counts(dds)) >= 10, ]

# ------------------------------------------------------------
# 6) Normalisierung: Size Factors sch√§tzen
#    DESeq2 nutzt "median-of-ratios" (robust gegen Outlier/Geneffekte)
# ------------------------------------------------------------
dds <- estimateSizeFactors(dds)

# Size factors inspizieren (sollten grob um 1 liegen; Unterschiede = Library size etc.)
sf <- sizeFactors(dds)
print(sf)

# ------------------------------------------------------------
# 7) Normalisierte Counts extrahieren
#    Diese Matrix ist sinnvoll f√ºr:
#      - PCA / Heatmaps / Plots
#    NICHT sinnvoll als Input f√ºr DESeq2-DE-Tests (die arbeiten mit Rohcounts + Modell)
# ------------------------------------------------------------
normalized_counts <- counts(dds, normalized = TRUE)

# ------------------------------------------------------------
# 8) Speichern
# ------------------------------------------------------------
write.table(
  normalized_counts,
  file = "../../res/normalized_counts_aortic_DESeq2.tsv",
  sep = "\t",
  quote = FALSE,
  col.names = NA
)
```

```{r}
### ============================================================
### Quality Control (QC) ‚Äì DESeq2 RNA-seq
### ============================================================

# ------------------------------------------------------------
# 1) Varianz-stabilisierende Transformation
# ------------------------------------------------------------
trans <- vst(dds, blind = TRUE)

# ------------------------------------------------------------
# 2) PCA ‚Äì schnelle √úbersicht
# ------------------------------------------------------------
plotPCA(trans, intgroup = "timepoint")

# ------------------------------------------------------------
# 3) PCA ‚Äì angepasstes ggplot (PC1 vs PC2)
# ------------------------------------------------------------
pca_df <- plotPCA(trans, intgroup = "timepoint", returnData = TRUE)
percentVar <- round(100 * attr(pca_df, "percentVar"))

ggplot(pca_df, aes(x = PC1, y = PC2, color = timepoint)) +
  geom_point(size = 3) +
  xlab(paste0("PC1: ", percentVar[1], "% Varianz")) +
  ylab(paste0("PC2: ", percentVar[2], "% Varianz")) +
  theme_minimal()

# ------------------------------------------------------------
# 4) PCA ‚Äì h√∂here Komponenten (PC3 vs PC4) mit vst-Matrix
# ------------------------------------------------------------
trans_mat <- assay(trans)        # Gene x Samples
pca <- prcomp(t(trans_mat))      # PCA auf Samples

df_pc <- cbind(
  as.data.frame(colData(dds)),
  as.data.frame(pca$x)
)

ggplot(df_pc, aes(x = PC3, y = PC4, color = timepoint)) +
  geom_point(size = 3) +
  theme_minimal()

##Die PCAs clustern eher nicht nach Timepoint, weil der Patienteneffekt > Timepoint-Effekt. Die Expression eines Patienten √ºber mehrere Zeitpunkte ist √§hnlicher als die Expression verschiedener Patienten √ºber einem Zeitpunkt.
# ------------------------------------------------------------
# 5) Hierarchisches Clustering ‚Äì Sample-Sample-Korrelation + Heatmap
# ------------------------------------------------------------
sample_cor <- cor(trans_mat)     # Samples x Samples

anno <- as.data.frame(colData(dds)[, "timepoint", drop = FALSE])
anno$timepoint <- factor(anno$timepoint)

anno <- anno[match(colnames(sample_cor), rownames(anno)), , drop = FALSE]
stopifnot(all(rownames(anno) == colnames(sample_cor)))

pheatmap(sample_cor,
         annotation_col = anno,
         show_colnames = FALSE,
         show_rownames = FALSE,
         breaks = seq(0.9, 1, length.out = 100) #damit werden feine Unterschiede                                                    etwas sichtbarer
         )
##Heatmap zeigt hohe Korrelationen, was f√ºr technisch saubere Daten spricht

```

```{r}
# ============================================================
# DESeq2 DE-Analyse nur wenn n√∂tig (Caching via RDS-Dateien)
# - Rechnet DESeq(dds) nur, wenn fitted dds noch nicht gespeichert ist
# - Berechnet/ speichert Result- und Shrinkage-Tabellen nur, wenn nicht vorhanden
# Voraussetzung: Objekt 'dds' (unfitted) existiert bereits in der Session
# ============================================================

# Speicherorte
cache_dir <- "../../res/cache"
if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

dds_cache_file <- file.path(cache_dir, "dds_DESeq_fitted.rds")

# 1) Fitted dds laden oder berechnen
if (file.exists(dds_cache_file)) {

  message("Lade bereits berechnetes DESeq2-Objekt: ", dds_cache_file)
  dds <- readRDS(dds_cache_file)

} else {

  message("Berechne DESeq2 (kann dauern)‚Ä¶")

  # sicherstellen, dass timepoint korrekt als Faktor vorliegt
  colData(dds)$timepoint <- factor(colData(dds)$timepoint, levels = c("A", "V1", "V2"))

  # Design setzen
  design(dds) <- ~ pid + timepoint

  # Prefiltering
  dds <- dds[rowSums(counts(dds)) >= 10, ]

  # DESeq laufen lassen
  dds <- DESeq(dds)

  # speichern
  saveRDS(dds, dds_cache_file)
  message("Gespeichert: ", dds_cache_file)
}

# ------------------------------------------------------------
# Helper: RDS-first caching (optional zus√§tzlich CSV-Export)
# ------------------------------------------------------------
run_or_load_rds <- function(rds_path, compute_expr, csv_path = NULL) {
  if (file.exists(rds_path)) {
    message("Lade: ", rds_path)
    return(readRDS(rds_path))
  }

  message("Berechne & speichere: ", rds_path)
  out <- eval(compute_expr)

  saveRDS(out, rds_path)

  if (!is.null(csv_path)) {
    # F√ºr Sharing/Excel etc. (Attributes gehen in CSV verloren ‚Äì ist okay)
    write.csv(as.data.frame(out), csv_path)
    message("Zus√§tzlich als CSV exportiert: ", csv_path)
  }

  out
}

# ------------------------------------------------------------
# 2) Raw Results (Wald-Tests) + RDS/CSV Cache
# ------------------------------------------------------------
alpha_level <- 0.05

res_dir <- "../../res"
if (!dir.exists(res_dir)) dir.create(res_dir, recursive = TRUE)

res_V1_vs_A_rds  <- file.path(cache_dir, "DESeq2_results_V1_vs_A.rds")
res_V2_vs_A_rds  <- file.path(cache_dir, "DESeq2_results_V2_vs_A.rds")
res_V2_vs_V1_rds <- file.path(cache_dir, "DESeq2_results_V2_vs_V1.rds")

res_V1_vs_A_csv  <- file.path(res_dir, "DESeq2_results_V1_vs_A.csv")
res_V2_vs_A_csv  <- file.path(res_dir, "DESeq2_results_V2_vs_A.csv")
res_V2_vs_V1_csv <- file.path(res_dir, "DESeq2_results_V2_vs_V1.csv")

res_V1_vs_A <- run_or_load_rds(
  rds_path = res_V1_vs_A_rds,
  csv_path = res_V1_vs_A_csv,
  compute_expr = quote(
    results(dds, contrast = c("timepoint", "V1", "A"), alpha = alpha_level)
  )
)

res_V2_vs_A <- run_or_load_rds(
  rds_path = res_V2_vs_A_rds,
  csv_path = res_V2_vs_A_csv,
  compute_expr = quote(
    results(dds, contrast = c("timepoint", "V2", "A"), alpha = alpha_level)
  )
)

res_V2_vs_V1 <- run_or_load_rds(
  rds_path = res_V2_vs_V1_rds,
  csv_path = res_V2_vs_V1_csv,
  compute_expr = quote(
    results(dds, contrast = c("timepoint", "V2", "V1"), alpha = alpha_level)
  )
)

# ------------------------------------------------------------
# 3) Shrinkage + RDS/CSV Cache
#    - apeglm via coef (f√ºr timepoint-Koeffizienten)
#    - ashr via contrast (geht gut f√ºr beliebige Kontraste)
#    - UND: res=... koppeln (Konsistenz)
# ------------------------------------------------------------
lfc_V1_vs_A_rds  <- file.path(cache_dir, "DESeq2_LFCshrink_V1_vs_A.rds")
lfc_V2_vs_A_rds  <- file.path(cache_dir, "DESeq2_LFCshrink_V2_vs_A.rds")
lfc_V2_vs_V1_rds <- file.path(cache_dir, "DESeq2_LFCshrink_V2_vs_V1.rds")

lfc_V1_vs_A_csv  <- file.path(res_dir, "DESeq2_LFCshrink_V1_vs_A.csv")
lfc_V2_vs_A_csv  <- file.path(res_dir, "DESeq2_LFCshrink_V2_vs_A.csv")
lfc_V2_vs_V1_csv <- file.path(res_dir, "DESeq2_LFCshrink_V2_vs_V1.csv")

# Safety checks f√ºr coef-Namen
rn <- resultsNames(dds)
message("resultsNames(dds): ", paste(rn, collapse = ", "))

stopifnot("timepoint_V1_vs_A" %in% rn)
stopifnot("timepoint_V2_vs_A" %in% rn)

resLFC_V1_vs_A <- run_or_load_rds(
  rds_path = lfc_V1_vs_A_rds,
  csv_path = lfc_V1_vs_A_csv,
  compute_expr = quote(
    lfcShrink(
      dds,
      coef = "timepoint_V1_vs_A",
      res  = res_V1_vs_A,
      type = "apeglm"
    )
  )
)

resLFC_V2_vs_A <- run_or_load_rds(
  rds_path = lfc_V2_vs_A_rds,
  csv_path = lfc_V2_vs_A_csv,
  compute_expr = quote(
    lfcShrink(
      dds,
      coef = "timepoint_V2_vs_A",
      res  = res_V2_vs_A,
      type = "apeglm"
    )
  )
)

resLFC_V2_vs_V1 <- run_or_load_rds(
  rds_path = lfc_V2_vs_V1_rds,
  csv_path = lfc_V2_vs_V1_csv,
  compute_expr = quote(
    lfcShrink(
      dds,
      contrast = c("timepoint", "V2", "V1"),
      res      = res_V2_vs_V1,
      type     = "ashr"
    )
  )
)
```

```{r}
#==============================================================
# Dispersionskurve, um zu sehen, ob es Auff√§lligkeiten gibt

plotDispEsts(dds)
# Kein Hinweis auf Batch-Effekte, systematische Fehlanpassung oder kaputte Shrinkage
```

```{r}

# ============================================================
# Unshrunken vs. shrunken LFC vergleichen (MA-Plots)
# ============================================================

# -------------------------
# V1 vs A
# -------------------------
res_V1_vs_A_unshrunken <- res_V1_vs_A

DESeq2::plotMA(
  res_V1_vs_A_unshrunken,
  ylim = c(-2, 2),
  main = "V1 vs A ‚Äì unshrunken"
)

DESeq2::plotMA(
  resLFC_V1_vs_A,
  ylim = c(-2, 2),
  main = "V1 vs A ‚Äì shrunken"
)

# -------------------------
# V2 vs A
# -------------------------
res_V2_vs_A_unshrunken <- res_V2_vs_A

DESeq2::plotMA(
  res_V2_vs_A_unshrunken,
  ylim = c(-2, 2),
  main = "V2 vs A ‚Äì unshrunken"
)

DESeq2::plotMA(
  resLFC_V2_vs_A,
  ylim = c(-2, 2),
  main = "V2 vs A ‚Äì shrunken"
)

# -------------------------
# V2 vs V1
# -------------------------
res_V2_vs_V1_unshrunken <- res_V2_vs_V1

DESeq2::plotMA(
  res_V2_vs_V1_unshrunken,
  ylim = c(-2, 2),
  main = "V2 vs V1 ‚Äì unshrunken"
)

DESeq2::plotMA(
  resLFC_V2_vs_V1,
  ylim = c(-2, 2),
  main = "V2 vs V1 ‚Äì shrunken"
)

```

```{r}
# ============================================================
# Summarizing results from the Wald test
# Ziel:
#  1) Ergebnisse je Vergleich mit summary() zusammenfassen (alpha explizit)
#  2) padj Cutoff setzen
#  3) DESeqResults -> tibble umwandeln
#  4) signifikante Gene herausfiltern (padj < cutoff)
#  5) (praktisch) Anzahl up/down z√§hlen + Genlisten erzeugen
# ============================================================

# ------------------------------------------------------------
# Schritt 1: Ergebnisse zusammenfassen mit summary()
# alpha explizit setzen, sonst ist Default padj < 0.1
# ------------------------------------------------------------
alpha_level <- 0.05

summary(res_V1_vs_A,  alpha = alpha_level)
summary(res_V2_vs_A,  alpha = alpha_level)
summary(res_V2_vs_V1, alpha = alpha_level)

# ------------------------------------------------------------
# Schritt 2: Schwellenwerte definieren
# ------------------------------------------------------------
padj_cutoff <- 0.05

# ------------------------------------------------------------
# Schritt 3: DESeqResults -> tibble konvertieren
# (damit man bequem filtern/arrangieren kann)
# ------------------------------------------------------------
res_V1_vs_A_tb <- res_V1_vs_A |>
  data.frame() |>
  rownames_to_column(var = "gene") |>
  as_tibble()

res_V2_vs_A_tb <- res_V2_vs_A |>
  data.frame() |>
  rownames_to_column(var = "gene") |>
  as_tibble()

res_V2_vs_V1_tb <- res_V2_vs_V1 |>
  data.frame() |>
  rownames_to_column(var = "gene") |>
  as_tibble()

# ------------------------------------------------------------
# Schritt 4: signifikante Gene extrahieren (padj < cutoff)
# !is.na(padj) explizit, damit NAs nicht ‚Äûdurchrutschen‚Äú
# ------------------------------------------------------------
sig_V1_vs_A <- dplyr::filter(
  res_V1_vs_A_tb,
  !is.na(padj),
  padj < padj_cutoff
)

sig_V2_vs_A <- dplyr::filter(
  res_V2_vs_A_tb,
  !is.na(padj),
  padj < padj_cutoff
)

sig_V2_vs_V1 <- dplyr::filter(
  res_V2_vs_V1_tb,
  !is.na(padj),
  padj < padj_cutoff
)

# Optional: kurz anschauen
sig_V1_vs_A
sig_V2_vs_A
sig_V2_vs_V1

# ------------------------------------------------------------
# Schritt 5:
# Up/Down z√§hlen und eine kleine √úbersicht bauen
# Up/Down bezieht sich auf das Vorzeichen von log2FoldChange
# ------------------------------------------------------------
count_up_down <- function(sig_tbl) {
  sig_tbl |>
    summarise(
      n_sig  = n(),
      n_up   = sum(log2FoldChange > 0, na.rm = TRUE),
      n_down = sum(log2FoldChange < 0, na.rm = TRUE)
    )
}

overview <- dplyr::bind_rows(
  count_up_down(sig_V1_vs_A)  |> dplyr::mutate(comparison = "V1 vs A"),
  count_up_down(sig_V2_vs_A)  |> dplyr::mutate(comparison = "V2 vs A"),
  count_up_down(sig_V2_vs_V1) |> dplyr::mutate(comparison = "V2 vs V1")
) |>
  dplyr::select(comparison, n_sig, n_up, n_down)

# ------------------------------------------------------------
# Schritt 6: Genlisten erzeugen (f√ºr Heatmaps/Enrichment etc.)
# ------------------------------------------------------------
genes_sig_V1_vs_A  <- sig_V1_vs_A$gene
genes_sig_V2_vs_A  <- sig_V2_vs_A$gene
genes_sig_V2_vs_V1 <- sig_V2_vs_V1$gene

#Top-Gene-Listen (z.B. nach padj sortiert)
top20_V1_vs_A <- sig_V1_vs_A |> arrange(padj) |> slice_head(n = 20)
top20_V2_vs_A <- sig_V2_vs_A |> arrange(padj) |> slice_head(n = 20)
top20_V2_vs_V1 <- sig_V2_vs_V1 |> arrange(padj) |> slice_head(n = 20)

# ggf: Export
# write.csv(sig_V1_vs_A,  "../../res/sig_V1_vs_A_padj05.csv", row.names = FALSE)
# write.csv(sig_V2_vs_A,  "../../res/sig_V2_vs_A_padj05.csv", row.names = FALSE)
# write.csv(sig_V2_vs_V1, "../../res/sig_V2_vs_V1_padj05.csv", row.names = FALSE)
# write.csv(overview,     "../../res/DE_summary_overview_padj05.csv", row.names = FALSE)

```

\# --- Meta vorbereiten ---

sample_meta \<- meta \|\>

rownames_to_column(var = "samplename") \|\>

as_tibble()

stopifnot(all(sample_meta\$samplename %in% colnames(normalized_counts)))

sample_meta \<- sample_meta \|\>

mutate(condition = droplevels(timepoint))

\# --- Normalisierte Counts als Tibble ---

norm_counts_tb \<- normalized_counts \|\>

as.data.frame() \|\>

rownames_to_column(var = "gene") \|\>

as_tibble()

\# --- Metadaten pro Kontrast filtern ---

meta_v1_a \<- sample_meta \|\> dplyr::filter(condition %in% c("A", "V1"))

meta_v2_a \<- sample_meta \|\> dplyr::filter(condition %in% c("A", "V2"))

meta_v2_v1 \<- sample_meta \|\> dplyr::filter(condition %in% c("V1", "V2"))

\# --- Plot-Funktion (mit +1 Pseudocount vor log10) ---

plot_top20_expression \<- function(res_tb, norm_counts_tb, meta_tb,

padj_cutoff = 0.05,

n_top = 20,

title = NULL) {

top_genes \<- res_tb \|\>

dplyr::filter(!is.na(padj), padj \< padj_cutoff) \|\>

dplyr::arrange(padj) \|\>

dplyr::slice_head(n = n_top) \|\>

dplyr::pull(gene)

plot_df \<- norm_counts_tb \|\>

dplyr::filter(gene %in% top_genes) \|\>

tidyr::pivot_longer(

cols = -gene,

names_to = "samplename",

values_to = "norm_count"

) \|\>

dplyr::inner_join(meta_tb, by = "samplename")

ggplot(plot_df, aes(x = gene, y = norm_count + 1, color = condition)) +

geom_point(position = position_jitter(width = 0.15), alpha = 0.8) +

scale_y_log10() +

labs(

title = title,

x = NULL,

y = "Normalized counts (log10, +1)",

color = "timepoint"

) +

theme_bw() +

theme(

axis.text.x = element_text(angle = 45, hjust = 1),

panel.grid.minor = element_blank()

)

}

\# --- Plots erzeugen ---

p_v1_a \<- plot_top20_expression(

res_tb = res_V1_vs_A_tb,

norm_counts_tb = norm_counts_tb,

meta_tb = meta_v1_a,

title = "Top 20 DE genes: V1 vs A"

)

p_v2_a \<- plot_top20_expression(

res_tb = res_V2_vs_A_tb,

norm_counts_tb = norm_counts_tb,

meta_tb = meta_v2_a,

title = "Top 20 DE genes: V2 vs A"

)

p_v2_v1 \<- plot_top20_expression(

res_tb = res_V2_vs_V1_tb,

norm_counts_tb = norm_counts_tb,

meta_tb = meta_v2_v1,

title = "Top 20 DE genes: V2 vs V1"

)

p_v1_a

p_v2_a

p_v2_v1

```{r}
# ============================================================
# DESeq2-Visualisierungen + Genannotation
#
# Inhalte:
#  1) Vorbereitung: Metadaten + normalisierte Counts
#  2) Genannotation (Ensembl -> SYMBOL/GENENAME), Ensembl-Versionen entfernen
#  3) Top-20-Expressionplots (Counts, nicht shrunken)
#  4) Volcano Plots (padj aus unshrunken results)
#  5) Heatmaps signifikanter Gene (pheatmap, Counts)
# ============================================================
# -----------------------------
# 1) Vorbereitung: Metadaten + Checks
# -----------------------------

# Metadaten in ein Tibble √ºberf√ºhren (Rownames = Sample-Namen sichern)
sample_meta <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  tibble::as_tibble() |>
  dplyr::mutate(
    # Zeitpunkte A/V1/V2 als Plot-/Gruppierungsfaktor nutzen
    condition = droplevels(timepoint)
  )

# Sicherstellen, dass Sample-Namen in meta auch in den Count-Spalten existieren
stopifnot(all(sample_meta$samplename %in% colnames(normalized_counts)))

# Normalisierte Counts als Tibble (praktisch f√ºr ggplot-Pipelines)
norm_counts_tb <- normalized_counts |>
  as.data.frame() |>
  tibble::rownames_to_column(var = "gene") |>
  tibble::as_tibble()

# -----------------------------
# 2) Genannotation: Ensembl-Version entfernen + SYMBOL/GENENAME erg√§nzen
# -----------------------------

# Ensembl-ID ohne Versionssuffix (ENSG... .16 -> ENSG...)
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# Mapping-Tabelle einmalig erzeugen (schneller als 3x select)
# Wir sammeln alle Ensembl-IDs aus allen Result-Tabellen.
all_ensembl <- unique(c(
  strip_ensembl_version(res_V1_vs_A_tb$gene),
  strip_ensembl_version(res_V2_vs_A_tb$gene),
  strip_ensembl_version(res_V2_vs_V1_tb$gene)
))

# Annotation ziehen: ENSEMBL -> SYMBOL + GENENAME
gene_anno <- AnnotationDbi::select(
  org.Hs.eg.db,
  keys = all_ensembl,
  keytype = "ENSEMBL",
  columns = c("SYMBOL", "GENENAME")
) |>
  dplyr::as_tibble() |>
  dplyr::rename(ensembl_id = ENSEMBL) |>
  # Doppelte Eintr√§ge k√∂nnen vorkommen (z.B. veraltete/mehrdeutige Mappings)
  # Wir behalten pro ensembl_id den ersten nicht-NA SYMBOL, sonst irgendeinen.
  dplyr::arrange(ensembl_id, dplyr::desc(!is.na(SYMBOL))) |>
  dplyr::distinct(ensembl_id, .keep_all = TRUE)

# Helper: Annotation an eine Results-Tabelle h√§ngen (gene bleibt unver√§ndert!)
add_gene_symbols <- function(res_tb, gene_anno) {
  res_tb |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene)) |>
    dplyr::left_join(gene_anno, by = "ensembl_id")
}

# Annotierte Results (f√ºr Tabellen/Interpretation/Labels)
res_V1_vs_A_annot  <- add_gene_symbols(res_V1_vs_A_tb, gene_anno)
res_V2_vs_A_annot  <- add_gene_symbols(res_V2_vs_A_tb, gene_anno)
res_V2_vs_V1_annot <- add_gene_symbols(res_V2_vs_V1_tb, gene_anno)

# Optional: auch signifikante Tabellen annotieren (praktisch f√ºr Exporte)
sig_V1_vs_A_annot  <- add_gene_symbols(sig_V1_vs_A, gene_anno)
sig_V2_vs_A_annot  <- add_gene_symbols(sig_V2_vs_A, gene_anno)
sig_V2_vs_V1_annot <- add_gene_symbols(sig_V2_vs_V1, gene_anno)

# Kurzer Sanity-Check
head(res_V1_vs_A_annot |> dplyr::select(gene, ensembl_id, SYMBOL, GENENAME), 10)
mean(is.na(res_V1_vs_A_annot$SYMBOL))

# -----------------------------
# 3) Kontrast-Definitionen zentral
# -----------------------------
contrasts <- list(
  v1_a = list(
    label = "V1 vs A",
    keep_levels = c("A", "V1"),
    res_tb = res_V1_vs_A_tb,
    res_annot = res_V1_vs_A_annot,
    sig_tb = sig_V1_vs_A,
    sig_annot = sig_V1_vs_A_annot
  ),
  v2_a = list(
    label = "V2 vs A",
    keep_levels = c("A", "V2"),
    res_tb = res_V2_vs_A_tb,
    res_annot = res_V2_vs_A_annot,
    sig_tb = sig_V2_vs_A,
    sig_annot = sig_V2_vs_A_annot
  ),
  v2_v1 = list(
    label = "V2 vs V1",
    keep_levels = c("V1", "V2"),
    res_tb = res_V2_vs_V1_tb,
    res_annot = res_V2_vs_V1_annot,
    sig_tb = sig_V2_vs_V1,
    sig_annot = sig_V2_vs_V1_annot
  )
)

# Helper: Metadaten f√ºr einen Kontrast (nur die relevanten Gruppen)
get_meta_for_contrast <- function(sample_meta, keep_levels) {
  sample_meta |>
    dplyr::filter(condition %in% keep_levels) |>
    droplevels()
}

# -----------------------------
# 4) Plot-Funktion: Top-20 Expression (Counts), mit +1 Pseudocount
# -----------------------------
plot_top20_expression <- function(res_tb, norm_counts_tb, meta_tb,
                                  padj_cutoff = 0.05,
                                  n_top = 20,
                                  title = NULL) {
  # Top-Gene nach padj (nur signifikante)
  top_genes <- res_tb |>
    dplyr::filter(!is.na(padj), padj < padj_cutoff) |>
    dplyr::arrange(padj) |>
    dplyr::slice_head(n = n_top) |>
    dplyr::pull(gene)

  plot_df <- norm_counts_tb |>
    dplyr::filter(gene %in% top_genes) |>
    tidyr::pivot_longer(
      cols = -gene,
      names_to = "samplename",
      values_to = "norm_count"
    ) |>
    dplyr::inner_join(meta_tb, by = "samplename")

  ggplot2::ggplot(plot_df, ggplot2::aes(x = gene, y = norm_count + 1, color = condition)) +
    ggplot2::geom_point(position = ggplot2::position_jitter(width = 0.15), alpha = 0.8) +
    ggplot2::scale_y_log10() +
    ggplot2::labs(
      title = title,
      x = NULL,
      y = "Normalisierte Counts (log10, +1)",
      color = "Zeitpunkt"
    ) +
    ggplot2::theme_bw() +
    ggplot2::theme(
      axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
      panel.grid.minor = ggplot2::element_blank()
    )
}

# -----------------------------
# 5) Plot-Funktion: Volcano Plot
# -----------------------------
plot_volcano <- function(res_tb, padj_cutoff = 0.05, title = NULL) {
  plot_df <- res_tb |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(
      neg_log10_padj = -log10(padj),
      sig = padj < padj_cutoff
    )

  ggplot2::ggplot(plot_df, ggplot2::aes(x = log2FoldChange, y = neg_log10_padj)) +
    ggplot2::geom_point(ggplot2::aes(color = sig), alpha = 0.6, size = 1.2) +
    ggplot2::scale_color_manual(values = c("FALSE" = "grey70", "TRUE" = "red")) +
    ggplot2::geom_hline(
      yintercept = -log10(padj_cutoff),
      linetype = "dashed"
    ) +
    ggplot2::labs(
      title = title,
      x = "log2 Fold Change",
      y = "-log10 adjustierter p-Wert",
      color = paste0("padj < ", padj_cutoff)
    ) +
    ggplot2::theme_bw()
}

# -----------------------------
# 6) Plot-Funktion: Heatmap signifikanter Gene (Counts, pheatmap)
# -----------------------------
plot_sig_heatmap <- function(normalized_counts, sample_meta, sig_genes, keep_levels,
                             heat_colors = RColorBrewer::brewer.pal(6, "YlOrRd"),
                             show_rownames = FALSE,
                             scale = "row",
                             main = NULL) {
  # Samples f√ºr diesen Kontrast
  samples_keep <- sample_meta |>
    dplyr::filter(condition %in% keep_levels) |>
    dplyr::pull(samplename)

  # Matrixsubset: nur signifikante Gene & relevante Samples
  mat <- normalized_counts[
    rownames(normalized_counts) %in% sig_genes,
    colnames(normalized_counts) %in% samples_keep,
    drop = FALSE
  ]

  if (nrow(mat) == 0) {
    stop("Keine signifikanten Gene f√ºr diesen Kontrast (nrow(mat) == 0).")
  }

  # Annotation f√ºr Spalten (Samples sind Spalten)
  annotation_col <- sample_meta |>
    dplyr::filter(samplename %in% colnames(mat)) |>
    dplyr::select(condition) |>
    as.data.frame()

  rownames(annotation_col) <- sample_meta |>
    dplyr::filter(samplename %in% colnames(mat)) |>
    dplyr::pull(samplename)

  pheatmap::pheatmap(
    mat,
    color = heat_colors,
    cluster_rows = TRUE,
    cluster_cols = TRUE,
    show_rownames = show_rownames,
    annotation_col = annotation_col,
    border_color = NA,
    fontsize = 10,
    scale = scale,
    main = main
  )
}

# ============================================================
# 7) Ausf√ºhren: Top-20, Volcano, Heatmaps f√ºr alle Kontraste
# ============================================================

padj_cutoff <- 0.05
heat_colors <- RColorBrewer::brewer.pal(6, "YlOrRd")

# --- Top-20 Expressionplots ---
top20_plots <- lapply(contrasts, function(x) {
  meta_sub <- get_meta_for_contrast(sample_meta, x$keep_levels)
  plot_top20_expression(
    res_tb = x$res_tb,
    norm_counts_tb = norm_counts_tb,
    meta_tb = meta_sub,
    padj_cutoff = padj_cutoff,
    n_top = 20,
    title = paste0("Top 20 DE-Gene: ", x$label)
  )
})

top20_plots$v1_a
top20_plots$v2_a
top20_plots$v2_v1

# --- Volcano Plots ---
volcano_plots <- lapply(contrasts, function(x) {
  plot_volcano(
    res_tb = x$res_tb,
    padj_cutoff = padj_cutoff,
    title = paste0("Volcano Plot: ", x$label)
  )
})

volcano_plots$v1_a
volcano_plots$v2_a
volcano_plots$v2_v1

# --- Heatmaps signifikanter Gene ---
# Hinweis: pheatmap zeichnet direkt; die Liste ist nur der Vollst√§ndigkeit halber.
heatmaps <- lapply(contrasts, function(x) {
  plot_sig_heatmap(
    normalized_counts = normalized_counts,
    sample_meta = sample_meta,
    sig_genes = x$sig_tb$gene,
    keep_levels = x$keep_levels,
    heat_colors = heat_colors,
    show_rownames = FALSE,
    scale = "row",
    main = paste0("Heatmap signifikanter Gene: ", x$label)
  )
})

# ============================================================
# 8) Top-Tabellen mit Gene Symbols (f√ºr Export/Interpretation)
# ============================================================

# Top 20 signifikante Gene mit SYMBOL f√ºr V1 vs A
top20_sig_v1_a <- sig_V1_vs_A_annot |>
  dplyr::filter(!is.na(padj)) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = 20) |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, log2FoldChange, padj)

top20_sig_v1_a

# Top 20 signifikante Gene mit SYMBOL f√ºr V2 vs A
top20_sig_v2_a <- sig_V2_vs_A_annot |>
  dplyr::filter(!is.na(padj)) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = 20) |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, log2FoldChange, padj)

top20_sig_v2_a


# Top 20 signifikante Gene mit SYMBOL f√ºr V2 vs V1
top20_sig_v2_v1 <- sig_V2_vs_V1_annot |>
  dplyr::filter(!is.na(padj)) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = 20) |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, log2FoldChange, padj)

top20_sig_v2_v1



```

```{r}
# ============================================================
# LRT-Analyse "nur wenn n√∂tig" (Caching via RDS)
# Full:    ~ pid + timepoint
# Reduced: ~ pid
# ============================================================


cache_dir <- "../../res/cache"
if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

dds_lrt_cache_file <- file.path(cache_dir, "dds_DESeq_LRT_fitted.rds")
res_lrt_rds        <- file.path(cache_dir, "DESeq2_results_LRT_timepoint.rds")
res_lrt_csv        <- file.path("../../res", "DESeq2_results_LRT_timepoint.csv")

# 1) LRT-fitted dds laden oder berechnen
if (file.exists(dds_lrt_cache_file)) {
  message("Lade bereits berechnetes LRT-DESeq2-Objekt: ", dds_lrt_cache_file)
  dds_lrt <- readRDS(dds_lrt_cache_file)
} else {
  message("Berechne DESeq2 LRT‚Ä¶")

  # Wichtig: hier NICHT dein bereits gefittetes dds √ºberschreiben,
  # sondern mit einem frischen Objekt arbeiten
  dds_lrt <- dds

  colData(dds_lrt)$timepoint <- factor(colData(dds_lrt)$timepoint, levels = c("A", "V1", "V2"))
  design(dds_lrt) <- ~ pid + timepoint

  # gleiches Prefiltering wie bei Wald (optional, aber konsistent)
  dds_lrt <- dds_lrt[rowSums(counts(dds_lrt)) >= 10, ]

  dds_lrt <- DESeq(dds_lrt, test = "LRT", reduced = ~ pid)

  saveRDS(dds_lrt, dds_lrt_cache_file)
  message("Gespeichert: ", dds_lrt_cache_file)
}

# 2) LRT-Results laden oder berechnen (nur 1 Results-Objekt, kein contrast!)
run_or_load_rds <- function(rds_path, compute_expr, csv_path = NULL) {
  if (file.exists(rds_path)) {
    message("Lade: ", rds_path)
    return(readRDS(rds_path))
  }
  message("Berechne & speichere: ", rds_path)
  out <- eval(compute_expr)
  saveRDS(out, rds_path)
  if (!is.null(csv_path)) {
    write.csv(as.data.frame(out), csv_path)
    message("Zus√§tzlich als CSV exportiert: ", csv_path)
  }
  out
}

res_lrt <- run_or_load_rds(
  rds_path = res_lrt_rds,
  csv_path = res_lrt_csv,
  compute_expr = quote(results(dds_lrt, alpha = 0.05))
)

summary(res_lrt)

```

```{r}
# ============================================================
# LRT Results weiterverarbeiten:
#  - res_lrt -> tibble
#  - Human Annotation (Ensembl -> SYMBOL/GENENAME)
#  - signifikante LRT-Gene
#  - Heatmap (alle Zeitpunkte)
# Voraussetzungen:
#  - res_lrt existiert (aus LRT-Caching-Chunk)
#  - meta und normalized_counts existieren (wie in Wald-Pipeline)
# ============================================================

# --- Helper: Ensembl-Versionen entfernen (ENSG... .16 -> ENSG...) ---
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# --- Metadaten wie bisher (f√ºr Heatmap-Annotation) ---
sample_meta <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  tibble::as_tibble() |>
  dplyr::mutate(
    condition = droplevels(timepoint),
    pid = as.factor(pid)
  )

stopifnot(all(sample_meta$samplename %in% colnames(normalized_counts)))

# --- 1) LRT-Results -> tibble ---
res_lrt_tb <- res_lrt |>
  as.data.frame() |>
  tibble::rownames_to_column(var = "gene") |>
  tibble::as_tibble() |>
  dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

# --- 2) Human Annotation (SYMBOL/GENENAME) ---
gene_anno <- AnnotationDbi::select(
  org.Hs.eg.db,
  keys = unique(res_lrt_tb$ensembl_id),
  keytype = "ENSEMBL",
  columns = c("SYMBOL", "GENENAME")
) |>
  tibble::as_tibble() |>
  dplyr::rename(ensembl_id = ENSEMBL) |>
  dplyr::arrange(ensembl_id, dplyr::desc(!is.na(SYMBOL))) |>
  dplyr::distinct(ensembl_id, .keep_all = TRUE)

res_lrt_annot <- res_lrt_tb |>
  dplyr::left_join(gene_anno, by = "ensembl_id")

# --- 3) Signifikante LRT-Gene (padj < 0.05), auf Top 200 begrenzen ---
padj_cutoff <- 0.05
n_heatmap <- 200

sig_lrt <- res_lrt_annot |>
  dplyr::filter(!is.na(padj), padj < padj_cutoff) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = n_heatmap)

# Optional: kurzer Blick auf die Top-Treffer
sig_lrt |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, pvalue, padj) |>
  dplyr::slice_head(n = 20)

# --- 4) Heatmap der LRT-signifikanten Gene √ºber ALLE Zeitpunkte (A/V1/V2) ---
# Matrix subset: Gene x Samples (pheatmap erwartet Matrix)
mat_lrt <- normalized_counts[
  strip_ensembl_version(rownames(normalized_counts)) %in% sig_lrt$ensembl_id,
  ,
  drop = FALSE
]

# einheitliche Rownames f√ºr stabiles Handling
rownames(mat_lrt) <- strip_ensembl_version(rownames(mat_lrt))

# Gene nach Signifikanz sortieren (optional)
gene_order <- sig_lrt$ensembl_id
mat_lrt <- mat_lrt[intersect(gene_order, rownames(mat_lrt)), , drop = FALSE]

# Spaltenannotation (Samples)
annotation_col <- sample_meta |>
  dplyr::select(samplename, condition) |>
  as.data.frame()

rownames(annotation_col) <- annotation_col$samplename
annotation_col$samplename <- NULL

# Farbpalette wie im HBC-Tutorial
heat_colors <- RColorBrewer::brewer.pal(6, "YlOrRd")

pheatmap::pheatmap(
  mat_lrt,
  color = heat_colors,
  cluster_rows = TRUE,
  cluster_cols = TRUE,
  show_rownames = FALSE,
  annotation_col = annotation_col,
  border_color = NA,
  fontsize = 10,
  scale = "row",
  main = paste0("LRT signifikante Gene (padj < ", padj_cutoff, ")")
)

```

```{r}
# ============================================================
# Wald vs. LRT Overlap (DESeq2)
# Ziel:
#   - Welche Gene sind im LRT (global √ºber A/V1/V2) signifikant
#     UND gleichzeitig in den paarweisen Wald-Kontrasten signifikant?
#
# Erwartete Objekte (so wie bei dir):
#   - sig_lrt        : tibble mit LRT-signifikanten Genen (mind. padj), ideal: Spalte `ensembl_id`
#   - res_lrt_annot  : annotierte LRT-Result-Tabelle (enth√§lt ensembl_id, SYMBOL, GENENAME, padj)
#   - sig_V1_vs_A    : tibble, Spalte `gene` (ENSG... mit Version)
#   - sig_V2_vs_A    : tibble, Spalte `gene`
#   - sig_V2_vs_V1   : tibble, Spalte `gene`
#
# Output:
#   - overlap_summary         : Tabelle mit Overlap-Zahlen
#   - overlap_genes_*         : Vektoren mit Ensembl IDs (ohne Version)
#   - overlap_annot_any_wald  : Top-Overlap-Gene annotiert (aus res_lrt_annot)
# ============================================================


# --- kleine Hilfsfunktion: ENSG0000... .16 -> ENSG0000... ---
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# ------------------------------------------------------------
# 1) IDs vorbereiten: LRT und Wald auf das gleiche ID-Format bringen
# ------------------------------------------------------------

# LRT: idealerweise hast du `ensembl_id` schon drin
# Falls nicht, bauen wir es aus `gene` nach
if (!"ensembl_id" %in% names(sig_lrt)) {
  stopifnot("gene" %in% names(sig_lrt))
  sig_lrt <- sig_lrt |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))
}

genes_lrt <- unique(sig_lrt$ensembl_id)

# Wald: bei dir liegen die Gene typischerweise als "ENSG... .version" in `gene`
stopifnot("gene" %in% names(sig_V1_vs_A))
stopifnot("gene" %in% names(sig_V2_vs_A))
stopifnot("gene" %in% names(sig_V2_vs_V1))

genes_wald_V1_vs_A  <- unique(strip_ensembl_version(sig_V1_vs_A$gene))
genes_wald_V2_vs_A  <- unique(strip_ensembl_version(sig_V2_vs_A$gene))
genes_wald_V2_vs_V1 <- unique(strip_ensembl_version(sig_V2_vs_V1$gene))

# einmal "alle Wald-Gene" zusammen (mind. ein Kontrast)
genes_wald_any <- unique(c(genes_wald_V1_vs_A, genes_wald_V2_vs_A, genes_wald_V2_vs_V1))

# ------------------------------------------------------------
# 2) Overlap berechnen
# ------------------------------------------------------------

# Overlap je Kontrast
overlap_genes_V1_vs_A  <- intersect(genes_lrt, genes_wald_V1_vs_A)
overlap_genes_V2_vs_A  <- intersect(genes_lrt, genes_wald_V2_vs_A)
overlap_genes_V2_vs_V1 <- intersect(genes_lrt, genes_wald_V2_vs_V1)

# Overlap: LRT ‚à© (irgendein Wald)
overlap_genes_any_wald <- intersect(genes_lrt, genes_wald_any)

# Auch ganz nett: was ist "nur LRT" vs. "nur Wald"?
genes_lrt_only  <- setdiff(genes_lrt, genes_wald_any)
genes_wald_only <- setdiff(genes_wald_any, genes_lrt)

# ------------------------------------------------------------
# 3) Kurz-Zusammenfassung als Tabelle (f√ºr Report/Thesis)
# ------------------------------------------------------------

overlap_summary <- tibble::tibble(
  category = c(
    "LRT signifikant (gesamt)",
    "Wald signifikant (irgendein Kontrast)",
    "Overlap: LRT ‚à© V1 vs A",
    "Overlap: LRT ‚à© V2 vs A",
    "Overlap: LRT ‚à© V2 vs V1",
    "Overlap: LRT ‚à© irgendein Wald",
    "Nur LRT (nicht in Wald)",
    "Nur Wald (nicht im LRT)"
  ),
  n_genes = c(
    length(genes_lrt),
    length(genes_wald_any),
    length(overlap_genes_V1_vs_A),
    length(overlap_genes_V2_vs_A),
    length(overlap_genes_V2_vs_V1),
    length(overlap_genes_any_wald),
    length(genes_lrt_only),
    length(genes_wald_only)
  )
)

overlap_summary

# ------------------------------------------------------------
# 4) Overlap-Gene annotiert anschauen (SYMBOL/GENENAME)
#    (wir nutzen res_lrt_annot als "Master", weil es Annotation enth√§lt)
# ------------------------------------------------------------

stopifnot(exists("res_lrt_annot"))
stopifnot("ensembl_id" %in% names(res_lrt_annot))

overlap_annot_any_wald <- res_lrt_annot |>
  dplyr::filter(ensembl_id %in% overlap_genes_any_wald) |>
  dplyr::select(ensembl_id, SYMBOL, GENENAME, pvalue, padj) |>
  dplyr::arrange(padj)

# Top 20 (optional)
overlap_annot_any_wald |> dplyr::slice_head(n = 20)

# ------------------------------------------------------------
# 5) Optional: Listen exportieren (falls du sie sp√§ter brauchst)
# ------------------------------------------------------------

# write.csv(overlap_summary, "../../res/overlap_Wald_LRT_summary.csv", row.names = FALSE)
# write.csv(overlap_annot_any_wald, "../../res/overlap_Wald_LRT_annot.csv", row.names = FALSE)

# Wenn du Genlisten als TXT brauchst:
# writeLines(overlap_genes_any_wald, "../../res/overlap_LRT_anyWald_genes.txt")

# ------------------------------------------------------------
# 6) Optional: Overlap nach Kontrast als kleine Tabelle
# ------------------------------------------------------------

overlap_by_contrast <- tibble::tibble(
  contrast = c("V1 vs A", "V2 vs A", "V2 vs V1"),
  n_overlap = c(
    length(overlap_genes_V1_vs_A),
    length(overlap_genes_V2_vs_A),
    length(overlap_genes_V2_vs_V1)
  )
)

overlap_by_contrast

```

```{r}
# ============================================================
# Heatmap nur der Wald‚à©LRT-Overlap-Gene
# Idee:
#   - LRT: Gene √§ndern sich global √ºber A/V1/V2
#   - Wald: Gene sind in mind. einem paarweisen Kontrast signifikant
#   - Overlap: "robuste" Kandidaten -> sch√∂ne Heatmap
#
# Voraussetzungen (wie bei dir):
#   - overlap_genes_any_wald  : Vektor (Ensembl IDs ohne Version) aus dem Overlap-Code
#   - normalized_counts       : Matrix (Gene x Samples), colnames = samplename
#   - meta                    : data.frame, rownames = samplename, enth√§lt timepoint
# Optional:
#   - res_lrt_annot            : f√ºr Gene-Labels (SYMBOL) ‚Äì nur wenn du willst
# ============================================================

strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# --- Metadaten f√ºr Annotation (Spalten = Samples) ---
sample_meta <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  tibble::as_tibble() |>
  dplyr::mutate(
    condition = droplevels(timepoint)
  )

stopifnot(all(sample_meta$samplename %in% colnames(normalized_counts)))

annotation_col <- sample_meta |>
  dplyr::select(samplename, condition) |>
  as.data.frame()

rownames(annotation_col) <- annotation_col$samplename
annotation_col$samplename <- NULL

# --- Matrix nur f√ºr Overlap-Gene (√ºber alle Samples / Zeitpunkte) ---
mat_overlap <- normalized_counts[
  strip_ensembl_version(rownames(normalized_counts)) %in% overlap_genes_any_wald,
  ,
  drop = FALSE
]

# Rownames vereinheitlichen (ohne Version), damit es sauber matcht
rownames(mat_overlap) <- strip_ensembl_version(rownames(mat_overlap))

# Optional: Gene in der Reihenfolge der Vektorliste darstellen (macht's reproduzierbar)
mat_overlap <- mat_overlap[intersect(overlap_genes_any_wald, rownames(mat_overlap)), , drop = FALSE]

# --- Optional: Heatmap begrenzen (falls es zu viele sind) ---
n_heatmap <- 200
if (nrow(mat_overlap) > n_heatmap) {
  set.seed(1)
  mat_overlap <- mat_overlap[seq_len(n_heatmap), , drop = FALSE]
}

# --- Optional: sch√∂nere Rowlabels mit SYMBOL (wenn res_lrt_annot vorhanden) ---
# Default: keine Rowlabels (wie im Tutorial oft)
show_row_names <- FALSE

if (exists("res_lrt_annot") && all(c("ensembl_id", "SYMBOL") %in% names(res_lrt_annot))) {
  # Mapping ensembl_id -> SYMBOL
  sym_map <- res_lrt_annot |>
    dplyr::select(ensembl_id, SYMBOL) |>
    dplyr::distinct() |>
    dplyr::filter(!is.na(SYMBOL))

  # Labels bauen: SYMBOL wenn vorhanden, sonst ENSG...
  rn <- rownames(mat_overlap)
  rn_sym <- sym_map$SYMBOL[match(rn, sym_map$ensembl_id)]
  rn_sym[is.na(rn_sym)] <- rn[is.na(rn_sym)]
  rownames(mat_overlap) <- rn_sym
}

# --- Farben wie HBC ---
heat_colors <- RColorBrewer::brewer.pal(6, "YlOrRd")

pheatmap::pheatmap(
  mat_overlap,
  color = heat_colors,
  cluster_rows = TRUE,
  cluster_cols = TRUE,
  show_rownames = show_row_names,  # FALSE = lesbarer bei vielen Genen
  annotation_col = annotation_col,
  border_color = NA,
  fontsize = 10,
  scale = "row",
  main = paste0(
    "Overlap-Heatmap (LRT ‚à© Wald), n = ",
    nrow(mat_overlap),
    if (exists("n_heatmap")) paste0(" (max ", n_heatmap, ")") else ""
  )
)
```

```{r}
# ============================================================
# Pattern-Clustering der Wald‚à©LRT-Overlap-Gene mit DEGreport
# Ziel:
#   - sch√∂ne, interpretierbare Zeitverlaufs-Plots
#   - basierend auf robusten Genen (LRT ‚à© Wald)
#
# Voraussetzungen:
#   - overlap_genes_any_wald : Ensembl IDs (ohne Version)
#   - normalized_counts     : Matrix (Gene x Samples)
#   - meta                  : data.frame, rownames = samplename
# ============================================================

# ------------------------------------------------------------
# Helper: Ensembl-Versionen entfernen (ENSG... .16 -> ENSG...)
# ------------------------------------------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# ------------------------------------------------------------
# 1) Metadaten f√ºr degPatterns vorbereiten
#    WICHTIG:
#    - metadata MUSS ein data.frame sein
#    - rownames(metadata) = Sample-Namen
# ------------------------------------------------------------
meta_deg <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  dplyr::select(samplename, timepoint) |>
  dplyr::mutate(condition = droplevels(timepoint)) |>
  as.data.frame()

rownames(meta_deg) <- meta_deg$samplename
meta_deg$samplename <- NULL

# Sanity-Check
stopifnot(all(rownames(meta_deg) %in% colnames(normalized_counts)))

# ------------------------------------------------------------
# 2) Matrix f√ºr Overlap-Gene bauen (Gene x Samples)
# ------------------------------------------------------------
mat_overlap <- normalized_counts[
  strip_ensembl_version(rownames(normalized_counts)) %in% overlap_genes_any_wald,
  ,
  drop = FALSE
]

# Rownames vereinheitlichen
rownames(mat_overlap) <- strip_ensembl_version(rownames(mat_overlap))

# Spaltenreihenfolge exakt an Metadaten anpassen
mat_overlap <- mat_overlap[, rownames(meta_deg), drop = FALSE]

# Optional: begrenzen, falls es zu viele Gene sind
n_max <- 500
if (nrow(mat_overlap) > n_max) {
  mat_overlap <- mat_overlap[seq_len(n_max), , drop = FALSE]
}

# ------------------------------------------------------------
# 3) degPatterns laufen lassen
# ------------------------------------------------------------
degPatterns(
  mat_overlap,
  metadata = meta_deg,
  time = "condition",
  minc = 30
)

# ============================================================
# Interpretation:
#   - Jeder Panel = ein Cluster / zeitliches Muster
#   - Punkte = einzelne Gene
#   - Linien = mittlerer Verlauf pro Cluster
#
# Ein gro√üer Teil der LRT‚à©Wald-Gene zeigt ein transient erh√∂htes Expressionsniveau bei V1 mit anschlie√üender R√ºckkehr zu Baseline bei V2
# ============================================================

```

```{r}

# ============================================================
# GO ORA (Over-Representation Analysis) ‚Äì DESeq2 Wald + LRT
# MIT CACHING (Summary-RDS) ‚Äì Copy-paste Block ans Ende deines Skripts
#
# Erwartete Objekte:
#   - res_V1_vs_A_tb, res_V2_vs_A_tb, res_V2_vs_V1_tb  (tibbles; gene, padj, log2FoldChange)
#   - res_lrt_tb (tibble; gene, padj) ODER res_lrt (DESeqResults)
#   - org.Hs.eg.db (Human)
#
# Output:
#   - ../../res/functional/ora_go/        (CSV + RDS + Dotplots)
#   - ../../res/cache/ora_go/             (Summary-Caches als RDS)
# ============================================================

# -----------------------------
# Helpers
# -----------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

.ensure_tbl_results <- function(x) {
  if (inherits(x, "DESeqResults")) {
    x |>
      as.data.frame() |>
      tibble::rownames_to_column(var = "gene") |>
      tibble::as_tibble()
  } else {
    tibble::as_tibble(x)
  }
}

.build_lists_for_ora <- function(res_tb, padj_cutoff = 0.05, lfc_col = "log2FoldChange") {
  res_tb <- .ensure_tbl_results(res_tb) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  universe <- unique(res_tb$ensembl_id)

  sig <- res_tb |>
    dplyr::filter(padj < padj_cutoff)

  sig_all <- unique(sig$ensembl_id)

  if (lfc_col %in% names(sig)) {
    sig_up <- unique(sig |> dplyr::filter(.data[[lfc_col]] > 0) |> dplyr::pull(ensembl_id))
    sig_down <- unique(sig |> dplyr::filter(.data[[lfc_col]] < 0) |> dplyr::pull(ensembl_id))
  } else {
    # LRT hat kein log2FoldChange
    sig_up <- character(0)
    sig_down <- character(0)
  }

  list(
    universe = universe,
    sig_all = sig_all,
    sig_up = sig_up,
    sig_down = sig_down
  )
}

.run_enrichgo <- function(sig_vec, universe_vec, ont = "BP",
                          p_adjust_method = "BH", q_cutoff = 0.05) {
  if (length(sig_vec) < 5) {
    return(NULL)
  }

  clusterProfiler::enrichGO(
    gene = sig_vec,
    universe = universe_vec,
    OrgDb = org.Hs.eg.db,
    keyType = "ENSEMBL",
    ont = ont,
    pAdjustMethod = p_adjust_method,
    qvalueCutoff = q_cutoff,
    readable = TRUE
  )
}

.save_enrichment <- function(enrich_obj, out_dir, stem,
                             make_plots = TRUE, show_category = 25) {
  if (is.null(enrich_obj)) {
    return(invisible(NULL))
  }

  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

  tab <- as.data.frame(enrich_obj)
  write.csv(tab, file.path(out_dir, paste0(stem, ".csv")), row.names = FALSE)
  saveRDS(enrich_obj, file.path(out_dir, paste0(stem, ".rds")))

  if (isTRUE(make_plots) && nrow(tab) > 0) {
    p <- enrichplot::dotplot(enrich_obj, showCategory = show_category) +
      ggplot2::ggtitle(stem) +
      ggplot2::theme_bw()

    ggplot2::ggsave(
      filename = file.path(out_dir, paste0(stem, "_dotplot.png")),
      plot = p,
      width = 9,
      height = 6,
      dpi = 200
    )
  }

  invisible(tab)
}

# -----------------------------
# Main: GO ORA f√ºr ein Set (Kontrast oder LRT) ‚Äì ohne Cache
# -----------------------------
run_go_ora_set <- function(res_obj,
                           set_label,
                           padj_cutoff = 0.05,
                           ontologies = c("BP", "MF", "CC"),
                           directions = c("all", "up", "down"),
                           out_dir = "../../res/functional/ora_go",
                           make_plots = TRUE) {
  lists <- .build_lists_for_ora(res_obj, padj_cutoff = padj_cutoff)

  summary_rows <- list()

  for (ont in ontologies) {
    for (dir in directions) {
      sig_vec <- switch(
        dir,
        all  = lists$sig_all,
        up   = lists$sig_up,
        down = lists$sig_down
      )

      # LRT: up/down ggf. leer -> skip
      if (length(sig_vec) == 0) next

      ego <- .run_enrichgo(sig_vec, lists$universe, ont = ont)

      stem <- paste0(
        "GO_", ont, "_", set_label, "_", dir,
        "_padj", format(padj_cutoff, nsmall = 2)
      )

      tab <- .save_enrichment(
        enrich_obj = ego,
        out_dir = out_dir,
        stem = stem,
        make_plots = make_plots,
        show_category = 25
      )

      if (is.null(tab) || nrow(tab) == 0) {
        summary_rows[[length(summary_rows) + 1]] <- tibble::tibble(
          set = set_label,
          ontology = ont,
          direction = dir,
          n_sig_genes = length(sig_vec),
          n_terms = 0L,
          top_term = NA_character_,
          top_term_padj = NA_real_
        )
      } else {
        summary_rows[[length(summary_rows) + 1]] <- tibble::tibble(
          set = set_label,
          ontology = ont,
          direction = dir,
          n_sig_genes = length(sig_vec),
          n_terms = nrow(tab),
          top_term = tab$Description[1],
          top_term_padj = tab$p.adjust[1]
        )
      }
    }
  }

  summary_tbl <- dplyr::bind_rows(summary_rows)

  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  write.csv(
    summary_tbl,
    file.path(
      out_dir,
      paste0("GO_ORA_summary_", set_label, "_padj", format(padj_cutoff, nsmall = 2), ".csv")
    ),
    row.names = FALSE
  )

  summary_tbl
}

# -----------------------------
# Caching Wrapper: l√§dt Summary-RDS, sonst rechnet + cach

```

```{r}
# ============================================================
# GO ORA Plots (wie HBC) f√ºr alle Kontraste ‚Äì automatisch
#   - dotplot (Top 50 by gene ratio)
#   - emapplot (term similarity / enrichmap)
#   - cnetplot (Top 5 terms; Genes colored by log2FC)
#
# Nutzt die bereits gespeicherten enrichGO-Objekte (*.rds) aus ora_out_dir
#
# Erwartete Objekte aus deinem Skript:
#   - ora_out_dir (Pfad wie im ORA-Block), padj_cutoff
#   - res_V1_vs_A_tb, res_V2_vs_A_tb, res_V2_vs_V1_tb (tibbles; gene, padj, log2FoldChange)
#   - res_lrt_tb (tibble; gene, padj) ODER res_lrt (DESeqResults)
#
# Output:
#   - ../../res/functional/ora_go/plots/
#       GO_BP_Wald_V1_vs_A_all_padj0.05_dotplot.png
#       GO_BP_Wald_V1_vs_A_all_padj0.05_emapplot.png
#       GO_BP_Wald_V1_vs_A_all_padj0.05_cnetplot.png
#       ...
# ============================================================

# -----------------------------
# Settings
# -----------------------------
# Falls du im ORA-Block bereits ora_out_dir gesetzt hast, nimm das:
if (!exists("ora_out_dir")) ora_out_dir <- "../../res/functional/ora_go"
if (!exists("padj_cutoff")) padj_cutoff <- 0.05

plots_dir <- file.path(ora_out_dir, "plots")
dir.create(plots_dir, recursive = TRUE, showWarnings = FALSE)

# HBC-Defaults
show_dot <- 50
show_emap <- 50
show_cnet <- 5

# Ontology: HBC zeigt BP (du kannst auch c("BP","MF","CC") setzen)
ontologies <- c("BP")

# -----------------------------
# Helpers
# -----------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

.ensure_tbl_results <- function(x) {
  if (inherits(x, "DESeqResults")) {
    x |>
      as.data.frame() |>
      tibble::rownames_to_column(var = "gene") |>
      tibble::as_tibble()
  } else {
    tibble::as_tibble(x)
  }
}

# Erzeuge FoldChange-Vektor (names=Ensembl ohne Version) passend zu enrichGO(keyType="ENSEMBL")
.make_foldchange_vec <- function(res_obj, padj_cutoff = 0.05, direction = c("all", "up", "down")) {
  direction <- match.arg(direction)

  res_tb <- .ensure_tbl_results(res_obj) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  # LRT hat kein log2FoldChange -> NA zur√ºck
  if (!"log2FoldChange" %in% names(res_tb)) {
    return(NULL)
  }

  sig <- res_tb |>
    dplyr::filter(padj < padj_cutoff)

  if (direction == "up") {
    sig <- sig |> dplyr::filter(log2FoldChange > 0)
  } else if (direction == "down") {
    sig <- sig |> dplyr::filter(log2FoldChange < 0)
  }

  fc <- sig$log2FoldChange
  names(fc) <- sig$ensembl_id

  # Falls Duplikate existieren (selten, aber m√∂glich): ersten behalten
  fc <- fc[!duplicated(names(fc))]
  fc
}

# Lade enrichGO-Objekt aus deinem ORA-Output anhand des gleichen stems wie im ORA-Block
.load_ego <- function(out_dir, ont, set_label, direction, padj_cutoff) {
  stem <- paste0(
    "GO_", ont, "_", set_label, "_", direction,
    "_padj", format(padj_cutoff, nsmall = 2)
  )
  rds_path <- file.path(out_dir, paste0(stem, ".rds"))

  if (!file.exists(rds_path)) {
    message("Skip (fehlendes RDS): ", rds_path)
    return(NULL)
  }

  ego <- readRDS(rds_path)

  # Leere Ergebnisse skippen
  tab <- tryCatch(as.data.frame(ego), error = function(e) NULL)
  if (is.null(tab) || nrow(tab) == 0) {
    message("Skip (0 Terms): ", stem)
    return(NULL)
  }

  list(ego = ego, stem = stem)
}

# Plot speichern (PNG)
.save_plot <- function(p, filename, width = 10, height = 7, dpi = 200) {
  ggplot2::ggsave(
    filename = filename,
    plot = p,
    width = width,
    height = height,
    dpi = dpi
  )
}

# Ein Set (Kontrast) plotten: dotplot + emapplot + cnetplot
.plot_go_set <- function(res_obj, set_label,
                         directions = c("all", "up", "down"),
                         ontologies = c("BP"),
                         out_dir = ora_out_dir,
                         padj_cutoff = 0.05) {
  for (ont in ontologies) {
    for (dir in directions) {
      loaded <- .load_ego(out_dir, ont, set_label, dir, padj_cutoff)
      if (is.null(loaded)) next

      ego <- loaded$ego
      stem <- loaded$stem

      # -----------------
      # 1) Dotplot (HBC)
      # -----------------
      p_dot <- enrichplot::dotplot(ego, showCategory = show_dot) +
        ggplot2::ggtitle(paste0(stem, " ‚Äì dotplot")) +
        ggplot2::theme_bw()

      .save_plot(
        p_dot,
        file.path(plots_dir, paste0(stem, "_dotplot.png")),
        width = 11, height = 7
      )

      # -----------------
      # 2) Enrichment map (HBC: pairwise_termsim + emapplot)
      # -----------------
      # (optional cache: termsim-Objekt als RDS speichern, spart Zeit beim n√§chsten Lauf)
      termsim_rds <- file.path(out_dir, paste0(stem, "_termsim.rds"))
      if (file.exists(termsim_rds)) {
        ego_ts <- readRDS(termsim_rds)
      } else {
        ego_ts <- enrichplot::pairwise_termsim(ego)
        saveRDS(ego_ts, termsim_rds)
      }

      p_emap <- enrichplot::emapplot(ego_ts, showCategory = show_emap) +
        ggplot2::ggtitle(paste0(stem, " ‚Äì emapplot")) +
        ggplot2::theme_void()

      .save_plot(
        p_emap,
        file.path(plots_dir, paste0(stem, "_emapplot.png")),
        width = 12, height = 9
      )

      # -----------------
      # 3) Category netplot (HBC: cnetplot + FoldChange)
      #     - nur wenn log2FC existiert (Wald), nicht beim LRT
      # -----------------
      fc <- .make_foldchange_vec(res_obj, padj_cutoff = padj_cutoff, direction = dir)

      if (!is.null(fc) && length(fc) >= 5) {
        # Hinweis aus HBC: ggf. ggnewscale installieren, falls n√∂tig
        # install.packages("ggnewscale")
        p_cnet <- enrichplot::cnetplot(
          ego_ts,
          showCategory = show_cnet,
          foldChange = fc
        ) +
          ggplot2::ggtitle(paste0(stem, " ‚Äì cnetplot")) +
          ggplot2::theme_void()

        .save_plot(
          p_cnet,
          file.path(plots_dir, paste0(stem, "_cnetplot.png")),
          width = 13, height = 9
        )
      } else {
        message("Skip cnetplot (kein log2FC oder zu wenige FC-Werte): ", stem)
      }
    }
  }
}

# ============================================================
# RUN: Wald-Kontraste + LRT (wie in deinem ORA-Block)
# ============================================================

# Wald: all/up/down
.plot_go_set(res_V1_vs_A_tb,  set_label = "Wald_V1_vs_A",
             directions = c("all", "up", "down"),
             ontologies = ontologies,
             out_dir = ora_out_dir, padj_cutoff = padj_cutoff)

.plot_go_set(res_V2_vs_A_tb,  set_label = "Wald_V2_vs_A",
             directions = c("all", "up", "down"),
             ontologies = ontologies,
             out_dir = ora_out_dir, padj_cutoff = padj_cutoff)

.plot_go_set(res_V2_vs_V1_tb, set_label = "Wald_V2_vs_V1",
             directions = c("all", "up", "down"),
             ontologies = ontologies,
             out_dir = ora_out_dir, padj_cutoff = padj_cutoff)

# LRT: nur all (kein log2FC -> kein cnetplot)
lrt_input <- if (exists("res_lrt_tb")) res_lrt_tb else res_lrt

.plot_go_set(lrt_input, set_label = "LRT_timepoint",
             directions = c("all"),
             ontologies = ontologies,
             out_dir = ora_out_dir, padj_cutoff = padj_cutoff)

message("Fertig. Plots liegen hier: ", normalizePath(plots_dir))

```
