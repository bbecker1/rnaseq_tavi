---
title: "DEanalysis"
----v
---

<https://hbctraining.github.io/Intro-to-DGE/schedule/links-to-lessons.html>

```{r}
#Pakete werden aus Setup Skript geladen
source("../../org/setup_packages.R")

suppressPackageStartupMessages(
{library(tidyverse)  
library(readxl)
library(janitor)
library(DESeq2)
library(tximport)
library(pheatmap)
library(RColorBrewer)
library(ggrepel)
library(cowplot)
library(DEGreport)
library(clusterProfiler)
library(DOSE)
library(org.Hs.eg.db)
library(pathview)
library(AnnotationHub)
library(ensembldb)
library(apeglm)
library(ashr)
})
sessionInfo()
```

## Datenimport und Vorbereitung

Dieser Chunk importiert die Salmon-Quantifizierungen mittels `tximport`, liest die Metadata aus Excel ein, f√ºhrt Quality Checks durch und erstellt ein Subset nur f√ºr Aortenklappen-Samples.

```{r}
#| echo: false
#| warning: false
# Pfade
salmon <- "../../dat/salmon_files"
tx2g   <- "../../dat/info_files/tx2gene.tsv"
excel  <- "../../dat/info_files/CCGA_sequencing_NM_ventricular_dysfunction_RNAseq_2342.xlsx"

# Salmon-Files einlesen
files <- list.files(
  path      = salmon,
  full.names = TRUE,
  pattern   = "_quant\\.sf$"
)

# Saubere Namen f√ºr tximport
names(files) <- basename(files) %>%
  str_remove("_quant\\.sf$") %>%    # Endung entfernen
  str_remove("-L[0-9]+$")           # evtl. Library-Nummer entfernen

# Duplikate ausschlie√üen
stopifnot(length(files) > 1)
stopifnot(!anyDuplicated(names(files)))

# tx2gene einlesen
tx2gene <- read.delim(tx2g)
tx2gene[,1] <- sub("\\..*$", "", tx2gene[,1])  # Versionsnummer entfernen
tx2gene <- tx2gene[, c(1,2)]                    # Nur tx_id und gene_id

# tximport
txi_cache <- "../../res/cache/txi_salmon_tximport.rds"
dir.create(dirname(txi_cache), recursive = TRUE, showWarnings = FALSE)

if (file.exists(txi_cache)) {
  message("‚úÖ Lade tximport Cache: ", txi_cache)
  txi <- readRDS(txi_cache)
} else {
  message("‚è≥ Rechne tximport‚Ä¶")
  txi <- tximport(
    files,
    type = "salmon",
    tx2gene = tx2gene,
    countsFromAbundance = "lengthScaledTPM",
    ignoreTxVersion = TRUE
  )
  saveRDS(txi, txi_cache)
  message("üíæ Gespeichert: ", txi_cache)
}

# Sample-Namen in txi bereinigen
colnames(txi$counts)    <- str_remove(colnames(txi$counts), "_quant\\.sf$")
colnames(txi$abundance) <- str_remove(colnames(txi$abundance), "_quant\\.sf$")
colnames(txi$length)    <- str_remove(colnames(txi$length), "_quant\\.sf$")

# Metadata einlesen
md <- read_excel(excel, sheet = "Metadata", skip = 1) %>%
  janitor::clean_names() %>%
  mutate(sample_id = str_remove(library_id, "-L[0-9]+$") %>% str_trim())

input <- read_excel(excel, sheet = 3, skip = 1) %>%
  janitor::clean_names() %>%
  mutate(
    valve_treated = if_else(str_starts(sample_name, regex("^t", TRUE)),
                            "tricuspid valve",
                            "aortic valve"),
    timepoint = str_extract(sample_name, "(?<=_).*"),
    pid       = str_extract(sample_name, "^[^_]+")
  ) %>%
  dplyr::select(external_id, valve_treated, timepoint, pid)

md <- left_join(md, input, by = "external_id")
stopifnot(all(!is.na(md$valve_treated)))

# ============================================================
# Diagnostik: Counts-Samples vs. Metadata-Samples
# ============================================================
counts_samples <- colnames(txi$counts)

in_counts_not_meta <- setdiff(counts_samples, md$sample_id)
in_meta_not_counts <- setdiff(md$sample_id, counts_samples)

message("Samples in counts but not metadata: ", length(in_counts_not_meta))
message("Samples in metadata but not counts: ", length(in_meta_not_counts))

if (length(in_counts_not_meta) > 0) {
  message("‚Üí In counts, not in metadata:")
  print(in_counts_not_meta)
}

if (length(in_meta_not_counts) > 0) {
  message("‚Üí In metadata, not in counts:")
  print(in_meta_not_counts)
}

# Abbrechen, wenn es Mismatches gibt
stopifnot(length(in_counts_not_meta) == 0, length(in_meta_not_counts) == 0)


# Nur Aorten-Samples behalten
keep_aortic <- intersect(colnames(txi$counts),
                         md$sample_id[md$valve_treated == "aortic valve"])

stopifnot(length(keep_aortic) > 1)
stopifnot(!anyDuplicated(keep_aortic))

txi_aortic <- list(
  counts             = txi$counts[, keep_aortic, drop = FALSE],
  abundance          = txi$abundance[, keep_aortic, drop = FALSE],
  length             = txi$length[, keep_aortic, drop = FALSE],
  countsFromAbundance = txi$countsFromAbundance
)


md_aortic <- md[md$sample_id %in% keep_aortic, ]

cat("Anzahl Aorten-Samples:", length(keep_aortic), "\n")
head(md_aortic)


```

## Explorative Datenanalyse (EDA)

Dieser Chunk visualisiert die Count-Verteilung und die Mean-Variance-Beziehung der RNA-seq Daten. Der Mean-Variance Plot zeigt Overdispersion (Varianz \>\> Mittelwert), was die Verwendung von Negativ-Binomial-Modellen (DESeq2) rechtfertigt.

```{r}
#| label: eda-counts
#| echo: false
#| warning: false

# Die Count-Verteilung einer einzelnen Probe ansehen
counts_aortic <- as.data.frame(txi_aortic$counts)

sample <- colnames(counts_aortic)[1]

ggplot(counts_aortic) +
  geom_histogram(aes(x = .data[[sample]]), bins = 200) +
  xlab("Raw expression counts") +
  ylab("Number of genes")

# Mean‚ÄìVariance Plot (RNA-seq count data) f√ºr Aorten-Counts

# 2) Mean und Varianz pro Gen (√ºber alle ausgew√§hlten Samples/Spalten)
mean_counts     <- apply(counts_aortic, 1, mean, na.rm = TRUE)  # '1' = zeilenweise (Gene)
variance_counts <- apply(counts_aortic, 1, var,  na.rm = TRUE)

# 3) Dataframe f√ºr ggplot
df_mv <- data.frame(
  mean_counts = mean_counts,
  variance_counts = variance_counts
)

# Gene mit mean/var <= 0 entfernen (log10 braucht > 0)
df_mv <- dplyr::filter(
  df_mv,
  mean_counts > 0,
  variance_counts > 0
)

# 4) Plot: log10-mean vs log10-variance, rote Linie = x=y
ggplot(df_mv) +
  geom_point(aes(x = mean_counts, y = variance_counts), alpha = 0.4) +
  scale_x_log10() +
  scale_y_log10() +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  labs(
    title = "Mean‚ÄìVariance Relationship (Aortic valve RNA-seq counts)",
    x = "Mean of counts per gene (log10)",
    y = "Variance of counts per gene (log10)"
  )
# Daten passen nicht zur Poission-Verteilung, weil die Varianz >> Mittelwert (Overdispersion). Besonders bei h√∂her exprimierten Genene ist die Varianz viel gr√∂√üer. Das rechtfertigt die Verwendung der Negativ-Binomial-Modelle von DESeq2
```

## DESeq2 Normalisierung

Dieser Chunk erstellt das DESeqDataSet-Objekt, f√ºhrt Prefiltering durch (rowSums \>= 10), sch√§tzt Size Factors mittels median-of-ratios Methode und exportiert normalisierte Counts. Die normalisierten Counts dienen nur der Visualisierung/QC, nicht als Input f√ºr DE-Tests.

```{r}
#| label: deseq2-normalization
#| echo: false
#| warning: false

# ------------------------------------------------------------
# 1) Metadata f√ºr DESeq2 vorbereiten
#    - sample_id muss character sein (IDs)
#    - pid/timepoint als factor (Design-Variablen)
#    - rownames(meta) m√ºssen exakt die Sample-IDs sein
# ------------------------------------------------------------
meta <- md_aortic %>%
  mutate(
    sample_id = as.character(sample_id),
    pid       = factor(pid),        # Patient-ID
    timepoint = factor(timepoint)   
  ) %>%
  as.data.frame()

rownames(meta) <- meta$sample_id

# ------------------------------------------------------------
# 2) Sicherstellen, dass Counts-Spalten und Metadata-Zeilen matchen
#    DESeq2 verlangt:
#      colnames(counts) == rownames(colData)
#    Reihenfolge ist wichtig (sonst falsche Zuordnung)
# ------------------------------------------------------------

# Check: alle Count-Sample-IDs existieren in meta?
stopifnot(all(colnames(txi_aortic$counts) %in% rownames(meta)))

# Meta exakt in die Reihenfolge der Count-Spalten bringen
meta <- meta[match(colnames(txi_aortic$counts), rownames(meta)), , drop = FALSE]

# Check: jetzt exakt identisch und in gleicher Reihenfolge?
stopifnot(all(colnames(txi_aortic$counts) == rownames(meta)))

# ------------------------------------------------------------
# 3) tximport-Metainfo erhalten
#    DESeqDataSetFromTximport() erwartet u.a. txi$countsFromAbundance
#    Wenn txi_aortic manuell als Liste gebaut wurde, fehlt das
# ------------------------------------------------------------
txi_aortic$countsFromAbundance <- txi$countsFromAbundance

# ------------------------------------------------------------
# 4) DESeqDataSet erstellen
#    Design: ~ pid + timepoint
#    - pid modelliert patientenspezifische Baselines
#    - timepoint testet die systematische √Ñnderung √ºber die Zeit
# ------------------------------------------------------------
dds <- DESeqDataSetFromTximport(
  txi = txi_aortic,
  colData = meta,
  design = ~ pid + timepoint
)

# ------------------------------------------------------------
# 5) Prefiltering:
#    Entfernt Gene mit extrem niedrigen Counts in allen Samples,
#    verbessert Laufzeit und reduziert Noise.
# ------------------------------------------------------------
dds <- dds[rowSums(counts(dds)) >= 10, ]

# ------------------------------------------------------------
# 6) Normalisierung: Size Factors sch√§tzen
#    DESeq2 nutzt "median-of-ratios" (robust gegen Outlier/Geneffekte)
# ------------------------------------------------------------
dds <- estimateSizeFactors(dds)

# Size factors inspizieren (sollten grob um 1 liegen; Unterschiede = Library size etc.)
sf <- sizeFactors(dds)
print(sf)

# ------------------------------------------------------------
# 7) Normalisierte Counts extrahieren
#    Diese Matrix ist sinnvoll f√ºr:
#      - PCA / Heatmaps / Plots
#    NICHT sinnvoll als Input f√ºr DESeq2-DE-Tests (die arbeiten mit Rohcounts + Modell)
# ------------------------------------------------------------
normalized_counts <- counts(dds, normalized = TRUE)

# ------------------------------------------------------------
# 8) Speichern
# ------------------------------------------------------------
write.table(
  normalized_counts,
  file = "../../res/normalized_counts_aortic_DESeq2.tsv",
  sep = "\t",
  quote = FALSE,
  col.names = NA
)
```

```{r}
### ============================================================
### Quality Control (QC) ‚Äì DESeq2 RNA-seq
### ============================================================

# ------------------------------------------------------------
# 1) Varianz-stabilisierende Transformation
# ------------------------------------------------------------
trans <- vst(dds, blind = TRUE)

# ------------------------------------------------------------
# 2) PCA ‚Äì schnelle √úbersicht
# ------------------------------------------------------------
plotPCA(trans, intgroup = "timepoint")

# ------------------------------------------------------------
# 3) PCA ‚Äì angepasstes ggplot (PC1 vs PC2)
# ------------------------------------------------------------
pca_df <- plotPCA(trans, intgroup = "timepoint", returnData = TRUE)
percentVar <- round(100 * attr(pca_df, "percentVar"))

ggplot(pca_df, aes(x = PC1, y = PC2, color = timepoint)) +
  geom_point(size = 3) +
  xlab(paste0("PC1: ", percentVar[1], "% Varianz")) +
  ylab(paste0("PC2: ", percentVar[2], "% Varianz")) +
  theme_minimal()

# ------------------------------------------------------------
# 4) PCA ‚Äì h√∂here Komponenten (PC3 vs PC4) mit vst-Matrix
# ------------------------------------------------------------
trans_mat <- assay(trans)        # Gene x Samples
pca <- prcomp(t(trans_mat))      # PCA auf Samples

df_pc <- cbind(
  as.data.frame(colData(dds)),
  as.data.frame(pca$x)
)

ggplot(df_pc, aes(x = PC3, y = PC4, color = timepoint)) +
  geom_point(size = 3) +
  theme_minimal()

##Die PCAs clustern eher nicht nach Timepoint, weil der Patienteneffekt > Timepoint-Effekt. Die Expression eines Patienten √ºber mehrere Zeitpunkte ist √§hnlicher als die Expression verschiedener Patienten √ºber einem Zeitpunkt.
# ------------------------------------------------------------
# 5) Hierarchisches Clustering ‚Äì Sample-Sample-Korrelation + Heatmap
# ------------------------------------------------------------
sample_cor <- cor(trans_mat)     # Samples x Samples

anno <- as.data.frame(colData(dds)[, "timepoint", drop = FALSE])
anno$timepoint <- factor(anno$timepoint)

anno <- anno[match(colnames(sample_cor), rownames(anno)), , drop = FALSE]
stopifnot(all(rownames(anno) == colnames(sample_cor)))

pheatmap(sample_cor,
         annotation_col = anno,
         show_colnames = FALSE,
         show_rownames = FALSE,
         breaks = seq(0.9, 1, length.out = 100) #damit werden feine Unterschiede                                                    etwas sichtbarer
         )
##Heatmap zeigt hohe Korrelationen, was f√ºr technisch saubere Daten spricht

```

```{r}
# ============================================================
# DESeq2 DE-Analyse nur wenn n√∂tig (Caching via RDS-Dateien)
# - Rechnet DESeq(dds) nur, wenn fitted dds noch nicht gespeichert ist
# - Berechnet/ speichert Result- und Shrinkage-Tabellen nur, wenn nicht vorhanden
# Voraussetzung: Objekt 'dds' (unfitted) existiert bereits in der Session
# ============================================================

# Speicherorte
cache_dir <- "../../res/cache"
if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

dds_cache_file <- file.path(cache_dir, "dds_DESeq_fitted.rds")

# 1) Fitted dds laden oder berechnen
if (file.exists(dds_cache_file)) {

  message("Lade bereits berechnetes DESeq2-Objekt: ", dds_cache_file)
  dds <- readRDS(dds_cache_file)

} else {

  message("Berechne DESeq2 (kann dauern)‚Ä¶")

  # sicherstellen, dass timepoint korrekt als Faktor vorliegt
  colData(dds)$timepoint <- factor(colData(dds)$timepoint, levels = c("A", "V1", "V2"))

  # Design setzen
  design(dds) <- ~ pid + timepoint

  # Prefiltering
  dds <- dds[rowSums(counts(dds)) >= 10, ]

  # DESeq laufen lassen
  dds <- DESeq(dds)

  # speichern
  saveRDS(dds, dds_cache_file)
  message("Gespeichert: ", dds_cache_file)
}

# ------------------------------------------------------------
# Helper: RDS-first caching (optional zus√§tzlich CSV-Export)
# ------------------------------------------------------------
run_or_load_rds <- function(rds_path, compute_expr, csv_path = NULL) {
  if (file.exists(rds_path)) {
    message("Lade: ", rds_path)
    return(readRDS(rds_path))
  }

  message("Berechne & speichere: ", rds_path)
  out <- eval(compute_expr)

  saveRDS(out, rds_path)

  if (!is.null(csv_path)) {
    # F√ºr Sharing/Excel etc. (Attributes gehen in CSV verloren ‚Äì ist okay)
    write.csv(as.data.frame(out), csv_path)
    message("Zus√§tzlich als CSV exportiert: ", csv_path)
  }

  out
}

# ------------------------------------------------------------
# 2) Raw Results (Wald-Tests) + RDS/CSV Cache
# ------------------------------------------------------------
alpha_level <- 0.05

res_dir <- "../../res"
if (!dir.exists(res_dir)) dir.create(res_dir, recursive = TRUE)

res_V1_vs_A_rds  <- file.path(cache_dir, "DESeq2_results_V1_vs_A.rds")
res_V2_vs_A_rds  <- file.path(cache_dir, "DESeq2_results_V2_vs_A.rds")
res_V2_vs_V1_rds <- file.path(cache_dir, "DESeq2_results_V2_vs_V1.rds")

res_V1_vs_A_csv  <- file.path(res_dir, "DESeq2_results_V1_vs_A.csv")
res_V2_vs_A_csv  <- file.path(res_dir, "DESeq2_results_V2_vs_A.csv")
res_V2_vs_V1_csv <- file.path(res_dir, "DESeq2_results_V2_vs_V1.csv")

res_V1_vs_A <- run_or_load_rds(
  rds_path = res_V1_vs_A_rds,
  csv_path = res_V1_vs_A_csv,
  compute_expr = quote(
    results(dds, contrast = c("timepoint", "V1", "A"), alpha = alpha_level)
  )
)

res_V2_vs_A <- run_or_load_rds(
  rds_path = res_V2_vs_A_rds,
  csv_path = res_V2_vs_A_csv,
  compute_expr = quote(
    results(dds, contrast = c("timepoint", "V2", "A"), alpha = alpha_level)
  )
)

res_V2_vs_V1 <- run_or_load_rds(
  rds_path = res_V2_vs_V1_rds,
  csv_path = res_V2_vs_V1_csv,
  compute_expr = quote(
    results(dds, contrast = c("timepoint", "V2", "V1"), alpha = alpha_level)
  )
)

# ------------------------------------------------------------
# 3) Shrinkage + RDS/CSV Cache
#    - apeglm via coef (f√ºr timepoint-Koeffizienten)
#    - ashr via contrast (geht gut f√ºr beliebige Kontraste)
#    - UND: res=... koppeln (Konsistenz)
# ------------------------------------------------------------
lfc_V1_vs_A_rds  <- file.path(cache_dir, "DESeq2_LFCshrink_V1_vs_A.rds")
lfc_V2_vs_A_rds  <- file.path(cache_dir, "DESeq2_LFCshrink_V2_vs_A.rds")
lfc_V2_vs_V1_rds <- file.path(cache_dir, "DESeq2_LFCshrink_V2_vs_V1.rds")

lfc_V1_vs_A_csv  <- file.path(res_dir, "DESeq2_LFCshrink_V1_vs_A.csv")
lfc_V2_vs_A_csv  <- file.path(res_dir, "DESeq2_LFCshrink_V2_vs_A.csv")
lfc_V2_vs_V1_csv <- file.path(res_dir, "DESeq2_LFCshrink_V2_vs_V1.csv")

# Safety checks f√ºr coef-Namen
rn <- resultsNames(dds)
message("resultsNames(dds): ", paste(rn, collapse = ", "))

stopifnot("timepoint_V1_vs_A" %in% rn)
stopifnot("timepoint_V2_vs_A" %in% rn)

resLFC_V1_vs_A <- run_or_load_rds(
  rds_path = lfc_V1_vs_A_rds,
  csv_path = lfc_V1_vs_A_csv,
  compute_expr = quote(
    lfcShrink(
      dds,
      coef = "timepoint_V1_vs_A",
      res  = res_V1_vs_A,
      type = "apeglm"
    )
  )
)

resLFC_V2_vs_A <- run_or_load_rds(
  rds_path = lfc_V2_vs_A_rds,
  csv_path = lfc_V2_vs_A_csv,
  compute_expr = quote(
    lfcShrink(
      dds,
      coef = "timepoint_V2_vs_A",
      res  = res_V2_vs_A,
      type = "apeglm"
    )
  )
)

resLFC_V2_vs_V1 <- run_or_load_rds(
  rds_path = lfc_V2_vs_V1_rds,
  csv_path = lfc_V2_vs_V1_csv,
  compute_expr = quote(
    lfcShrink(
      dds,
      contrast = c("timepoint", "V2", "V1"),
      res      = res_V2_vs_V1,
      type     = "ashr"
    )
  )
)
```

```{r}
#==============================================================
# Dispersionskurve, um zu sehen, ob es Auff√§lligkeiten gibt

plotDispEsts(dds)
# Kein Hinweis auf Batch-Effekte, systematische Fehlanpassung oder kaputte Shrinkage
```

```{r}

# ============================================================
# Unshrunken vs. shrunken LFC vergleichen (MA-Plots)
# ============================================================

# -------------------------
# V1 vs A
# -------------------------
res_V1_vs_A_unshrunken <- res_V1_vs_A

DESeq2::plotMA(
  res_V1_vs_A_unshrunken,
  ylim = c(-2, 2),
  main = "V1 vs A ‚Äì unshrunken"
)

DESeq2::plotMA(
  resLFC_V1_vs_A,
  ylim = c(-2, 2),
  main = "V1 vs A ‚Äì shrunken"
)

# -------------------------
# V2 vs A
# -------------------------
res_V2_vs_A_unshrunken <- res_V2_vs_A

DESeq2::plotMA(
  res_V2_vs_A_unshrunken,
  ylim = c(-2, 2),
  main = "V2 vs A ‚Äì unshrunken"
)

DESeq2::plotMA(
  resLFC_V2_vs_A,
  ylim = c(-2, 2),
  main = "V2 vs A ‚Äì shrunken"
)

# -------------------------
# V2 vs V1
# -------------------------
res_V2_vs_V1_unshrunken <- res_V2_vs_V1

DESeq2::plotMA(
  res_V2_vs_V1_unshrunken,
  ylim = c(-2, 2),
  main = "V2 vs V1 ‚Äì unshrunken"
)

DESeq2::plotMA(
  resLFC_V2_vs_V1,
  ylim = c(-2, 2),
  main = "V2 vs V1 ‚Äì shrunken"
)

```

```{r}
# ============================================================
# Summarizing results from the Wald test
# Ziel:
#  1) Ergebnisse je Vergleich mit summary() zusammenfassen (alpha explizit)
#  2) padj Cutoff setzen
#  3) DESeqResults -> tibble umwandeln
#  4) signifikante Gene herausfiltern (padj < cutoff)
#  5) (praktisch) Anzahl up/down z√§hlen + Genlisten erzeugen
# ============================================================

# ------------------------------------------------------------
# Schritt 1: Ergebnisse zusammenfassen mit summary()
# alpha explizit setzen, sonst ist Default padj < 0.1
# ------------------------------------------------------------
alpha_level <- 0.05

summary(res_V1_vs_A,  alpha = alpha_level)
summary(res_V2_vs_A,  alpha = alpha_level)
summary(res_V2_vs_V1, alpha = alpha_level)

# ------------------------------------------------------------
# Schritt 2: Schwellenwerte definieren
# ------------------------------------------------------------
padj_cutoff <- 0.05

# ------------------------------------------------------------
# Schritt 3: DESeqResults -> tibble konvertieren
# (damit man bequem filtern/arrangieren kann)
# ------------------------------------------------------------
res_V1_vs_A_tb <- res_V1_vs_A |>
  data.frame() |>
  rownames_to_column(var = "gene") |>
  as_tibble()

res_V2_vs_A_tb <- res_V2_vs_A |>
  data.frame() |>
  rownames_to_column(var = "gene") |>
  as_tibble()

res_V2_vs_V1_tb <- res_V2_vs_V1 |>
  data.frame() |>
  rownames_to_column(var = "gene") |>
  as_tibble()

# ------------------------------------------------------------
# Schritt 4: signifikante Gene extrahieren (padj < cutoff)
# !is.na(padj) explizit, damit NAs nicht ‚Äûdurchrutschen‚Äú
# ------------------------------------------------------------
sig_V1_vs_A <- dplyr::filter(
  res_V1_vs_A_tb,
  !is.na(padj),
  padj < padj_cutoff
)

sig_V2_vs_A <- dplyr::filter(
  res_V2_vs_A_tb,
  !is.na(padj),
  padj < padj_cutoff
)

sig_V2_vs_V1 <- dplyr::filter(
  res_V2_vs_V1_tb,
  !is.na(padj),
  padj < padj_cutoff
)

# Optional: kurz anschauen
sig_V1_vs_A
sig_V2_vs_A
sig_V2_vs_V1

# ------------------------------------------------------------
# Schritt 5:
# Up/Down z√§hlen und eine kleine √úbersicht bauen
# Up/Down bezieht sich auf das Vorzeichen von log2FoldChange
# ------------------------------------------------------------
count_up_down <- function(sig_tbl) {
  sig_tbl |>
    summarise(
      n_sig  = n(),
      n_up   = sum(log2FoldChange > 0, na.rm = TRUE),
      n_down = sum(log2FoldChange < 0, na.rm = TRUE)
    )
}

overview <- dplyr::bind_rows(
  count_up_down(sig_V1_vs_A)  |> dplyr::mutate(comparison = "V1 vs A"),
  count_up_down(sig_V2_vs_A)  |> dplyr::mutate(comparison = "V2 vs A"),
  count_up_down(sig_V2_vs_V1) |> dplyr::mutate(comparison = "V2 vs V1")
) |>
  dplyr::select(comparison, n_sig, n_up, n_down)

# ------------------------------------------------------------
# Schritt 6: Genlisten erzeugen (f√ºr Heatmaps/Enrichment etc.)
# ------------------------------------------------------------
genes_sig_V1_vs_A  <- sig_V1_vs_A$gene
genes_sig_V2_vs_A  <- sig_V2_vs_A$gene
genes_sig_V2_vs_V1 <- sig_V2_vs_V1$gene

#Top-Gene-Listen (z.B. nach padj sortiert)
top20_V1_vs_A <- sig_V1_vs_A |> arrange(padj) |> slice_head(n = 20)
top20_V2_vs_A <- sig_V2_vs_A |> arrange(padj) |> slice_head(n = 20)
top20_V2_vs_V1 <- sig_V2_vs_V1 |> arrange(padj) |> slice_head(n = 20)

# ggf: Export
# write.csv(sig_V1_vs_A,  "../../res/sig_V1_vs_A_padj05.csv", row.names = FALSE)
# write.csv(sig_V2_vs_A,  "../../res/sig_V2_vs_A_padj05.csv", row.names = FALSE)
# write.csv(sig_V2_vs_V1, "../../res/sig_V2_vs_V1_padj05.csv", row.names = FALSE)
# write.csv(overview,     "../../res/DE_summary_overview_padj05.csv", row.names = FALSE)

```

\# --- Meta vorbereiten ---

sample_meta \<- meta \|\>

rownames_to_column(var = "samplename") \|\>

as_tibble()

stopifnot(all(sample_meta\$samplename %in% colnames(normalized_counts)))

sample_meta \<- sample_meta \|\>

mutate(condition = droplevels(timepoint))

\# --- Normalisierte Counts als Tibble ---

norm_counts_tb \<- normalized_counts \|\>

as.data.frame() \|\>

rownames_to_column(var = "gene") \|\>

as_tibble()

\# --- Metadaten pro Kontrast filtern ---

meta_v1_a \<- sample_meta \|\> dplyr::filter(condition %in% c("A", "V1"))

meta_v2_a \<- sample_meta \|\> dplyr::filter(condition %in% c("A", "V2"))

meta_v2_v1 \<- sample_meta \|\> dplyr::filter(condition %in% c("V1", "V2"))

\# --- Plot-Funktion (mit +1 Pseudocount vor log10) ---

plot_top20_expression \<- function(res_tb, norm_counts_tb, meta_tb,

padj_cutoff = 0.05,

n_top = 20,

title = NULL) {

top_genes \<- res_tb \|\>

dplyr::filter(!is.na(padj), padj \< padj_cutoff) \|\>

dplyr::arrange(padj) \|\>

dplyr::slice_head(n = n_top) \|\>

dplyr::pull(gene)

plot_df \<- norm_counts_tb \|\>

dplyr::filter(gene %in% top_genes) \|\>

tidyr::pivot_longer(

cols = -gene,

names_to = "samplename",

values_to = "norm_count"

) \|\>

dplyr::inner_join(meta_tb, by = "samplename")

ggplot(plot_df, aes(x = gene, y = norm_count + 1, color = condition)) +

geom_point(position = position_jitter(width = 0.15), alpha = 0.8) +

scale_y_log10() +

labs(

title = title,

x = NULL,

y = "Normalized counts (log10, +1)",

color = "timepoint"

) +

theme_bw() +

theme(

axis.text.x = element_text(angle = 45, hjust = 1),

panel.grid.minor = element_blank()

)

}

\# --- Plots erzeugen ---

p_v1_a \<- plot_top20_expression(

res_tb = res_V1_vs_A_tb,

norm_counts_tb = norm_counts_tb,

meta_tb = meta_v1_a,

title = "Top 20 DE genes: V1 vs A"

)

p_v2_a \<- plot_top20_expression(

res_tb = res_V2_vs_A_tb,

norm_counts_tb = norm_counts_tb,

meta_tb = meta_v2_a,

title = "Top 20 DE genes: V2 vs A"

)

p_v2_v1 \<- plot_top20_expression(

res_tb = res_V2_vs_V1_tb,

norm_counts_tb = norm_counts_tb,

meta_tb = meta_v2_v1,

title = "Top 20 DE genes: V2 vs V1"

)

p_v1_a

p_v2_a

p_v2_v1

```{r}
# ============================================================
# DESeq2-Visualisierungen + Genannotation
#
# Inhalte:
#  1) Vorbereitung: Metadaten + normalisierte Counts
#  2) Genannotation (Ensembl -> SYMBOL/GENENAME), Ensembl-Versionen entfernen
#  3) Top-20-Expressionplots (Counts, nicht shrunken)
#  4) Volcano Plots (padj aus unshrunken results)
#  5) Heatmaps signifikanter Gene (pheatmap, Counts)
# ============================================================
# -----------------------------
# 1) Vorbereitung: Metadaten + Checks
# -----------------------------

# Metadaten in ein Tibble √ºberf√ºhren (Rownames = Sample-Namen sichern)
sample_meta <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  tibble::as_tibble() |>
  dplyr::mutate(
    # Zeitpunkte A/V1/V2 als Plot-/Gruppierungsfaktor nutzen
    condition = droplevels(timepoint)
  )

# Sicherstellen, dass Sample-Namen in meta auch in den Count-Spalten existieren
stopifnot(all(sample_meta$samplename %in% colnames(normalized_counts)))

# Normalisierte Counts als Tibble (praktisch f√ºr ggplot-Pipelines)
norm_counts_tb <- normalized_counts |>
  as.data.frame() |>
  tibble::rownames_to_column(var = "gene") |>
  tibble::as_tibble()

# -----------------------------
# 2) Genannotation: Ensembl-Version entfernen + SYMBOL/GENENAME erg√§nzen
# -----------------------------

# Ensembl-ID ohne Versionssuffix (ENSG... .16 -> ENSG...)
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# Mapping-Tabelle einmalig erzeugen (schneller als 3x select)
# Wir sammeln alle Ensembl-IDs aus allen Result-Tabellen.
all_ensembl <- unique(c(
  strip_ensembl_version(res_V1_vs_A_tb$gene),
  strip_ensembl_version(res_V2_vs_A_tb$gene),
  strip_ensembl_version(res_V2_vs_V1_tb$gene)
))

# Annotation ziehen: ENSEMBL -> SYMBOL + GENENAME
gene_anno <- AnnotationDbi::select(
  org.Hs.eg.db,
  keys = all_ensembl,
  keytype = "ENSEMBL",
  columns = c("SYMBOL", "GENENAME")
) |>
  dplyr::as_tibble() |>
  dplyr::rename(ensembl_id = ENSEMBL) |>
  # Doppelte Eintr√§ge k√∂nnen vorkommen (z.B. veraltete/mehrdeutige Mappings)
  # Wir behalten pro ensembl_id den ersten nicht-NA SYMBOL, sonst irgendeinen.
  dplyr::arrange(ensembl_id, dplyr::desc(!is.na(SYMBOL))) |>
  dplyr::distinct(ensembl_id, .keep_all = TRUE)

# Helper: Annotation an eine Results-Tabelle h√§ngen (gene bleibt unver√§ndert!)
add_gene_symbols <- function(res_tb, gene_anno) {
  res_tb |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene)) |>
    dplyr::left_join(gene_anno, by = "ensembl_id")
}

# Annotierte Results (f√ºr Tabellen/Interpretation/Labels)
res_V1_vs_A_annot  <- add_gene_symbols(res_V1_vs_A_tb, gene_anno)
res_V2_vs_A_annot  <- add_gene_symbols(res_V2_vs_A_tb, gene_anno)
res_V2_vs_V1_annot <- add_gene_symbols(res_V2_vs_V1_tb, gene_anno)

# Optional: auch signifikante Tabellen annotieren (praktisch f√ºr Exporte)
sig_V1_vs_A_annot  <- add_gene_symbols(sig_V1_vs_A, gene_anno)
sig_V2_vs_A_annot  <- add_gene_symbols(sig_V2_vs_A, gene_anno)
sig_V2_vs_V1_annot <- add_gene_symbols(sig_V2_vs_V1, gene_anno)

# Kurzer Sanity-Check
head(res_V1_vs_A_annot |> dplyr::select(gene, ensembl_id, SYMBOL, GENENAME), 10)
mean(is.na(res_V1_vs_A_annot$SYMBOL))

# -----------------------------
# 3) Kontrast-Definitionen zentral
# -----------------------------
contrasts <- list(
  v1_a = list(
    label = "V1 vs A",
    keep_levels = c("A", "V1"),
    res_tb = res_V1_vs_A_tb,
    res_annot = res_V1_vs_A_annot,
    sig_tb = sig_V1_vs_A,
    sig_annot = sig_V1_vs_A_annot
  ),
  v2_a = list(
    label = "V2 vs A",
    keep_levels = c("A", "V2"),
    res_tb = res_V2_vs_A_tb,
    res_annot = res_V2_vs_A_annot,
    sig_tb = sig_V2_vs_A,
    sig_annot = sig_V2_vs_A_annot
  ),
  v2_v1 = list(
    label = "V2 vs V1",
    keep_levels = c("V1", "V2"),
    res_tb = res_V2_vs_V1_tb,
    res_annot = res_V2_vs_V1_annot,
    sig_tb = sig_V2_vs_V1,
    sig_annot = sig_V2_vs_V1_annot
  )
)

# Helper: Metadaten f√ºr einen Kontrast (nur die relevanten Gruppen)
get_meta_for_contrast <- function(sample_meta, keep_levels) {
  sample_meta |>
    dplyr::filter(condition %in% keep_levels) |>
    droplevels()
}

# -----------------------------
# 4) Plot-Funktion: Top-20 Expression (Counts), mit +1 Pseudocount
# -----------------------------
plot_top20_expression <- function(res_tb, norm_counts_tb, meta_tb,
                                  padj_cutoff = 0.05,
                                  n_top = 20,
                                  title = NULL) {
  # Top-Gene nach padj (nur signifikante)
  top_genes <- res_tb |>
    dplyr::filter(!is.na(padj), padj < padj_cutoff) |>
    dplyr::arrange(padj) |>
    dplyr::slice_head(n = n_top) |>
    dplyr::pull(gene)

  plot_df <- norm_counts_tb |>
    dplyr::filter(gene %in% top_genes) |>
    tidyr::pivot_longer(
      cols = -gene,
      names_to = "samplename",
      values_to = "norm_count"
    ) |>
    dplyr::inner_join(meta_tb, by = "samplename")

  ggplot2::ggplot(plot_df, ggplot2::aes(x = gene, y = norm_count + 1, color = condition)) +
    ggplot2::geom_point(position = ggplot2::position_jitter(width = 0.15), alpha = 0.8) +
    ggplot2::scale_y_log10() +
    ggplot2::labs(
      title = title,
      x = NULL,
      y = "Normalisierte Counts (log10, +1)",
      color = "Zeitpunkt"
    ) +
    ggplot2::theme_bw() +
    ggplot2::theme(
      axis.text.x = ggplot2::element_text(angle = 45, hjust = 1),
      panel.grid.minor = ggplot2::element_blank()
    )
}

# -----------------------------
# 5) Plot-Funktion: Volcano Plot
# -----------------------------
plot_volcano <- function(res_tb, padj_cutoff = 0.05, title = NULL) {
  plot_df <- res_tb |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(
      neg_log10_padj = -log10(padj),
      sig = padj < padj_cutoff
    )

  ggplot2::ggplot(plot_df, ggplot2::aes(x = log2FoldChange, y = neg_log10_padj)) +
    ggplot2::geom_point(ggplot2::aes(color = sig), alpha = 0.6, size = 1.2) +
    ggplot2::scale_color_manual(values = c("FALSE" = "grey70", "TRUE" = "red")) +
    ggplot2::geom_hline(
      yintercept = -log10(padj_cutoff),
      linetype = "dashed"
    ) +
    ggplot2::labs(
      title = title,
      x = "log2 Fold Change",
      y = "-log10 adjustierter p-Wert",
      color = paste0("padj < ", padj_cutoff)
    ) +
    ggplot2::theme_bw()
}

# -----------------------------
# 6) Plot-Funktion: Heatmap signifikanter Gene (Counts, pheatmap)
# -----------------------------
plot_sig_heatmap <- function(normalized_counts, sample_meta, sig_genes, keep_levels,
                             heat_colors = RColorBrewer::brewer.pal(6, "YlOrRd"),
                             show_rownames = FALSE,
                             scale = "row",
                             main = NULL) {
  # Samples f√ºr diesen Kontrast
  samples_keep <- sample_meta |>
    dplyr::filter(condition %in% keep_levels) |>
    dplyr::pull(samplename)

  # Matrixsubset: nur signifikante Gene & relevante Samples
  mat <- normalized_counts[
    rownames(normalized_counts) %in% sig_genes,
    colnames(normalized_counts) %in% samples_keep,
    drop = FALSE
  ]

  if (nrow(mat) == 0) {
    stop("Keine signifikanten Gene f√ºr diesen Kontrast (nrow(mat) == 0).")
  }

  # Annotation f√ºr Spalten (Samples sind Spalten)
  annotation_col <- sample_meta |>
    dplyr::filter(samplename %in% colnames(mat)) |>
    dplyr::select(condition) |>
    as.data.frame()

  rownames(annotation_col) <- sample_meta |>
    dplyr::filter(samplename %in% colnames(mat)) |>
    dplyr::pull(samplename)

  pheatmap::pheatmap(
    mat,
    color = heat_colors,
    cluster_rows = TRUE,
    cluster_cols = TRUE,
    show_rownames = show_rownames,
    annotation_col = annotation_col,
    border_color = NA,
    fontsize = 10,
    scale = scale,
    main = main
  )
}

# ============================================================
# 7) Ausf√ºhren: Top-20, Volcano, Heatmaps f√ºr alle Kontraste
# ============================================================

padj_cutoff <- 0.05
heat_colors <- RColorBrewer::brewer.pal(6, "YlOrRd")

# --- Top-20 Expressionplots ---
top20_plots <- lapply(contrasts, function(x) {
  meta_sub <- get_meta_for_contrast(sample_meta, x$keep_levels)
  plot_top20_expression(
    res_tb = x$res_tb,
    norm_counts_tb = norm_counts_tb,
    meta_tb = meta_sub,
    padj_cutoff = padj_cutoff,
    n_top = 20,
    title = paste0("Top 20 DE-Gene: ", x$label)
  )
})

top20_plots$v1_a
top20_plots$v2_a
top20_plots$v2_v1

# --- Volcano Plots ---
volcano_plots <- lapply(contrasts, function(x) {
  plot_volcano(
    res_tb = x$res_tb,
    padj_cutoff = padj_cutoff,
    title = paste0("Volcano Plot: ", x$label)
  )
})

volcano_plots$v1_a
volcano_plots$v2_a
volcano_plots$v2_v1

# --- Heatmaps signifikanter Gene ---
# Hinweis: pheatmap zeichnet direkt; die Liste ist nur der Vollst√§ndigkeit halber.
heatmaps <- lapply(contrasts, function(x) {
  plot_sig_heatmap(
    normalized_counts = normalized_counts,
    sample_meta = sample_meta,
    sig_genes = x$sig_tb$gene,
    keep_levels = x$keep_levels,
    heat_colors = heat_colors,
    show_rownames = FALSE,
    scale = "row",
    main = paste0("Heatmap signifikanter Gene: ", x$label)
  )
})

# ============================================================
# 8) Top-Tabellen mit Gene Symbols (f√ºr Export/Interpretation)
# ============================================================

# Top 20 signifikante Gene mit SYMBOL f√ºr V1 vs A
top20_sig_v1_a <- sig_V1_vs_A_annot |>
  dplyr::filter(!is.na(padj)) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = 20) |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, log2FoldChange, padj)

top20_sig_v1_a

# Top 20 signifikante Gene mit SYMBOL f√ºr V2 vs A
top20_sig_v2_a <- sig_V2_vs_A_annot |>
  dplyr::filter(!is.na(padj)) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = 20) |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, log2FoldChange, padj)

top20_sig_v2_a


# Top 20 signifikante Gene mit SYMBOL f√ºr V2 vs V1
top20_sig_v2_v1 <- sig_V2_vs_V1_annot |>
  dplyr::filter(!is.na(padj)) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = 20) |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, log2FoldChange, padj)

top20_sig_v2_v1



```

```{r}
# ============================================================
# LRT-Analyse "nur wenn n√∂tig" (Caching via RDS)
# Full:    ~ pid + timepoint
# Reduced: ~ pid
# ============================================================


cache_dir <- "../../res/cache"
if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

dds_lrt_cache_file <- file.path(cache_dir, "dds_DESeq_LRT_fitted.rds")
res_lrt_rds        <- file.path(cache_dir, "DESeq2_results_LRT_timepoint.rds")
res_lrt_csv        <- file.path("../../res", "DESeq2_results_LRT_timepoint.csv")

# 1) LRT-fitted dds laden oder berechnen
if (file.exists(dds_lrt_cache_file)) {
  message("Lade bereits berechnetes LRT-DESeq2-Objekt: ", dds_lrt_cache_file)
  dds_lrt <- readRDS(dds_lrt_cache_file)
} else {
  message("Berechne DESeq2 LRT‚Ä¶")

  # Wichtig: hier NICHT dein bereits gefittetes dds √ºberschreiben,
  # sondern mit einem frischen Objekt arbeiten
  dds_lrt <- dds

  colData(dds_lrt)$timepoint <- factor(colData(dds_lrt)$timepoint, levels = c("A", "V1", "V2"))
  design(dds_lrt) <- ~ pid + timepoint

  # gleiches Prefiltering wie bei Wald (optional, aber konsistent)
  dds_lrt <- dds_lrt[rowSums(counts(dds_lrt)) >= 10, ]

  dds_lrt <- DESeq(dds_lrt, test = "LRT", reduced = ~ pid)

  saveRDS(dds_lrt, dds_lrt_cache_file)
  message("Gespeichert: ", dds_lrt_cache_file)
}

# 2) LRT-Results laden oder berechnen (nur 1 Results-Objekt, kein contrast!)
run_or_load_rds <- function(rds_path, compute_expr, csv_path = NULL) {
  if (file.exists(rds_path)) {
    message("Lade: ", rds_path)
    return(readRDS(rds_path))
  }
  message("Berechne & speichere: ", rds_path)
  out <- eval(compute_expr)
  saveRDS(out, rds_path)
  if (!is.null(csv_path)) {
    write.csv(as.data.frame(out), csv_path)
    message("Zus√§tzlich als CSV exportiert: ", csv_path)
  }
  out
}

res_lrt <- run_or_load_rds(
  rds_path = res_lrt_rds,
  csv_path = res_lrt_csv,
  compute_expr = quote(results(dds_lrt, alpha = 0.05))
)

summary(res_lrt)

```

```{r}
# ============================================================
# LRT Results weiterverarbeiten:
#  - res_lrt -> tibble
#  - Human Annotation (Ensembl -> SYMBOL/GENENAME)
#  - signifikante LRT-Gene
#  - Heatmap (alle Zeitpunkte)
# Voraussetzungen:
#  - res_lrt existiert (aus LRT-Caching-Chunk)
#  - meta und normalized_counts existieren (wie in Wald-Pipeline)
# ============================================================

# --- Helper: Ensembl-Versionen entfernen (ENSG... .16 -> ENSG...) ---
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# --- Metadaten wie bisher (f√ºr Heatmap-Annotation) ---
sample_meta <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  tibble::as_tibble() |>
  dplyr::mutate(
    condition = droplevels(timepoint),
    pid = as.factor(pid)
  )

stopifnot(all(sample_meta$samplename %in% colnames(normalized_counts)))

# --- 1) LRT-Results -> tibble ---
res_lrt_tb <- res_lrt |>
  as.data.frame() |>
  tibble::rownames_to_column(var = "gene") |>
  tibble::as_tibble() |>
  dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

# --- 2) Human Annotation (SYMBOL/GENENAME) ---
gene_anno <- AnnotationDbi::select(
  org.Hs.eg.db,
  keys = unique(res_lrt_tb$ensembl_id),
  keytype = "ENSEMBL",
  columns = c("SYMBOL", "GENENAME")
) |>
  tibble::as_tibble() |>
  dplyr::rename(ensembl_id = ENSEMBL) |>
  dplyr::arrange(ensembl_id, dplyr::desc(!is.na(SYMBOL))) |>
  dplyr::distinct(ensembl_id, .keep_all = TRUE)

res_lrt_annot <- res_lrt_tb |>
  dplyr::left_join(gene_anno, by = "ensembl_id")

# --- 3) Signifikante LRT-Gene (padj < 0.05), auf Top 200 begrenzen ---
padj_cutoff <- 0.05
n_heatmap <- 200

sig_lrt <- res_lrt_annot |>
  dplyr::filter(!is.na(padj), padj < padj_cutoff) |>
  dplyr::arrange(padj) |>
  dplyr::slice_head(n = n_heatmap)

# Optional: kurzer Blick auf die Top-Treffer
sig_lrt |>
  dplyr::select(gene, ensembl_id, SYMBOL, GENENAME, pvalue, padj) |>
  dplyr::slice_head(n = 20)

# --- 4) Heatmap der LRT-signifikanten Gene √ºber ALLE Zeitpunkte (A/V1/V2) ---
# Matrix subset: Gene x Samples (pheatmap erwartet Matrix)
mat_lrt <- normalized_counts[
  strip_ensembl_version(rownames(normalized_counts)) %in% sig_lrt$ensembl_id,
  ,
  drop = FALSE
]

# einheitliche Rownames f√ºr stabiles Handling
rownames(mat_lrt) <- strip_ensembl_version(rownames(mat_lrt))

# Gene nach Signifikanz sortieren (optional)
gene_order <- sig_lrt$ensembl_id
mat_lrt <- mat_lrt[intersect(gene_order, rownames(mat_lrt)), , drop = FALSE]

# Spaltenannotation (Samples)
annotation_col <- sample_meta |>
  dplyr::select(samplename, condition) |>
  as.data.frame()

rownames(annotation_col) <- annotation_col$samplename
annotation_col$samplename <- NULL

# Farbpalette wie im HBC-Tutorial
heat_colors <- RColorBrewer::brewer.pal(6, "YlOrRd")

pheatmap::pheatmap(
  mat_lrt,
  color = heat_colors,
  cluster_rows = TRUE,
  cluster_cols = TRUE,
  show_rownames = FALSE,
  annotation_col = annotation_col,
  border_color = NA,
  fontsize = 10,
  scale = "row",
  main = paste0("LRT signifikante Gene (padj < ", padj_cutoff, ")")
)

```

```{r}
# ============================================================
# Wald vs. LRT Overlap (DESeq2)
# Ziel:
#   - Welche Gene sind im LRT (global √ºber A/V1/V2) signifikant
#     UND gleichzeitig in den paarweisen Wald-Kontrasten signifikant?
#
# Erwartete Objekte (so wie bei dir):
#   - sig_lrt        : tibble mit LRT-signifikanten Genen (mind. padj), ideal: Spalte `ensembl_id`
#   - res_lrt_annot  : annotierte LRT-Result-Tabelle (enth√§lt ensembl_id, SYMBOL, GENENAME, padj)
#   - sig_V1_vs_A    : tibble, Spalte `gene` (ENSG... mit Version)
#   - sig_V2_vs_A    : tibble, Spalte `gene`
#   - sig_V2_vs_V1   : tibble, Spalte `gene`
#
# Output:
#   - overlap_summary         : Tabelle mit Overlap-Zahlen
#   - overlap_genes_*         : Vektoren mit Ensembl IDs (ohne Version)
#   - overlap_annot_any_wald  : Top-Overlap-Gene annotiert (aus res_lrt_annot)
# ============================================================


# --- kleine Hilfsfunktion: ENSG0000... .16 -> ENSG0000... ---
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# ------------------------------------------------------------
# 1) IDs vorbereiten: LRT und Wald auf das gleiche ID-Format bringen
# ------------------------------------------------------------

# LRT: idealerweise hast du `ensembl_id` schon drin
# Falls nicht, bauen wir es aus `gene` nach
if (!"ensembl_id" %in% names(sig_lrt)) {
  stopifnot("gene" %in% names(sig_lrt))
  sig_lrt <- sig_lrt |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))
}

genes_lrt <- unique(sig_lrt$ensembl_id)

# Wald: bei dir liegen die Gene typischerweise als "ENSG... .version" in `gene`
stopifnot("gene" %in% names(sig_V1_vs_A))
stopifnot("gene" %in% names(sig_V2_vs_A))
stopifnot("gene" %in% names(sig_V2_vs_V1))

genes_wald_V1_vs_A  <- unique(strip_ensembl_version(sig_V1_vs_A$gene))
genes_wald_V2_vs_A  <- unique(strip_ensembl_version(sig_V2_vs_A$gene))
genes_wald_V2_vs_V1 <- unique(strip_ensembl_version(sig_V2_vs_V1$gene))

# einmal "alle Wald-Gene" zusammen (mind. ein Kontrast)
genes_wald_any <- unique(c(genes_wald_V1_vs_A, genes_wald_V2_vs_A, genes_wald_V2_vs_V1))

# ------------------------------------------------------------
# 2) Overlap berechnen
# ------------------------------------------------------------

# Overlap je Kontrast
overlap_genes_V1_vs_A  <- intersect(genes_lrt, genes_wald_V1_vs_A)
overlap_genes_V2_vs_A  <- intersect(genes_lrt, genes_wald_V2_vs_A)
overlap_genes_V2_vs_V1 <- intersect(genes_lrt, genes_wald_V2_vs_V1)

# Overlap: LRT ‚à© (irgendein Wald)
overlap_genes_any_wald <- intersect(genes_lrt, genes_wald_any)

# Auch ganz nett: was ist "nur LRT" vs. "nur Wald"?
genes_lrt_only  <- setdiff(genes_lrt, genes_wald_any)
genes_wald_only <- setdiff(genes_wald_any, genes_lrt)

# ------------------------------------------------------------
# 3) Kurz-Zusammenfassung als Tabelle (f√ºr Report/Thesis)
# ------------------------------------------------------------

overlap_summary <- tibble::tibble(
  category = c(
    "LRT signifikant (gesamt)",
    "Wald signifikant (irgendein Kontrast)",
    "Overlap: LRT ‚à© V1 vs A",
    "Overlap: LRT ‚à© V2 vs A",
    "Overlap: LRT ‚à© V2 vs V1",
    "Overlap: LRT ‚à© irgendein Wald",
    "Nur LRT (nicht in Wald)",
    "Nur Wald (nicht im LRT)"
  ),
  n_genes = c(
    length(genes_lrt),
    length(genes_wald_any),
    length(overlap_genes_V1_vs_A),
    length(overlap_genes_V2_vs_A),
    length(overlap_genes_V2_vs_V1),
    length(overlap_genes_any_wald),
    length(genes_lrt_only),
    length(genes_wald_only)
  )
)

overlap_summary

# ------------------------------------------------------------
# 4) Overlap-Gene annotiert anschauen (SYMBOL/GENENAME)
#    (wir nutzen res_lrt_annot als "Master", weil es Annotation enth√§lt)
# ------------------------------------------------------------

stopifnot(exists("res_lrt_annot"))
stopifnot("ensembl_id" %in% names(res_lrt_annot))

overlap_annot_any_wald <- res_lrt_annot |>
  dplyr::filter(ensembl_id %in% overlap_genes_any_wald) |>
  dplyr::select(ensembl_id, SYMBOL, GENENAME, pvalue, padj) |>
  dplyr::arrange(padj)

# Top 20 (optional)
overlap_annot_any_wald |> dplyr::slice_head(n = 20)

# ------------------------------------------------------------
# 5) Optional: Listen exportieren (falls du sie sp√§ter brauchst)
# ------------------------------------------------------------

# write.csv(overlap_summary, "../../res/overlap_Wald_LRT_summary.csv", row.names = FALSE)
# write.csv(overlap_annot_any_wald, "../../res/overlap_Wald_LRT_annot.csv", row.names = FALSE)

# Wenn du Genlisten als TXT brauchst:
# writeLines(overlap_genes_any_wald, "../../res/overlap_LRT_anyWald_genes.txt")

# ------------------------------------------------------------
# 6) Optional: Overlap nach Kontrast als kleine Tabelle
# ------------------------------------------------------------

overlap_by_contrast <- tibble::tibble(
  contrast = c("V1 vs A", "V2 vs A", "V2 vs V1"),
  n_overlap = c(
    length(overlap_genes_V1_vs_A),
    length(overlap_genes_V2_vs_A),
    length(overlap_genes_V2_vs_V1)
  )
)

overlap_by_contrast

```

```{r}
# ============================================================
# Heatmap nur der Wald‚à©LRT-Overlap-Gene
# Idee:
#   - LRT: Gene √§ndern sich global √ºber A/V1/V2
#   - Wald: Gene sind in mind. einem paarweisen Kontrast signifikant
#   - Overlap: "robuste" Kandidaten -> sch√∂ne Heatmap
#
# Voraussetzungen (wie bei dir):
#   - overlap_genes_any_wald  : Vektor (Ensembl IDs ohne Version) aus dem Overlap-Code
#   - normalized_counts       : Matrix (Gene x Samples), colnames = samplename
#   - meta                    : data.frame, rownames = samplename, enth√§lt timepoint
# Optional:
#   - res_lrt_annot            : f√ºr Gene-Labels (SYMBOL) ‚Äì nur wenn du willst
# ============================================================

strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# --- Metadaten f√ºr Annotation (Spalten = Samples) ---
sample_meta <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  tibble::as_tibble() |>
  dplyr::mutate(
    condition = droplevels(timepoint)
  )

stopifnot(all(sample_meta$samplename %in% colnames(normalized_counts)))

annotation_col <- sample_meta |>
  dplyr::select(samplename, condition) |>
  as.data.frame()

rownames(annotation_col) <- annotation_col$samplename
annotation_col$samplename <- NULL

# --- Matrix nur f√ºr Overlap-Gene (√ºber alle Samples / Zeitpunkte) ---
mat_overlap <- normalized_counts[
  strip_ensembl_version(rownames(normalized_counts)) %in% overlap_genes_any_wald,
  ,
  drop = FALSE
]

# Rownames vereinheitlichen (ohne Version), damit es sauber matcht
rownames(mat_overlap) <- strip_ensembl_version(rownames(mat_overlap))

# Optional: Gene in der Reihenfolge der Vektorliste darstellen (macht's reproduzierbar)
mat_overlap <- mat_overlap[intersect(overlap_genes_any_wald, rownames(mat_overlap)), , drop = FALSE]

# --- Optional: Heatmap begrenzen (falls es zu viele sind) ---
n_heatmap <- 200
if (nrow(mat_overlap) > n_heatmap) {
  set.seed(1)
  mat_overlap <- mat_overlap[seq_len(n_heatmap), , drop = FALSE]
}

# --- Optional: sch√∂nere Rowlabels mit SYMBOL (wenn res_lrt_annot vorhanden) ---
# Default: keine Rowlabels (wie im Tutorial oft)
show_row_names <- FALSE

if (exists("res_lrt_annot") && all(c("ensembl_id", "SYMBOL") %in% names(res_lrt_annot))) {
  # Mapping ensembl_id -> SYMBOL
  sym_map <- res_lrt_annot |>
    dplyr::select(ensembl_id, SYMBOL) |>
    dplyr::distinct() |>
    dplyr::filter(!is.na(SYMBOL))

  # Labels bauen: SYMBOL wenn vorhanden, sonst ENSG...
  rn <- rownames(mat_overlap)
  rn_sym <- sym_map$SYMBOL[match(rn, sym_map$ensembl_id)]
  rn_sym[is.na(rn_sym)] <- rn[is.na(rn_sym)]
  rownames(mat_overlap) <- rn_sym
}

# --- Farben wie HBC ---
heat_colors <- RColorBrewer::brewer.pal(6, "YlOrRd")

pheatmap::pheatmap(
  mat_overlap,
  color = heat_colors,
  cluster_rows = TRUE,
  cluster_cols = TRUE,
  show_rownames = show_row_names,  # FALSE = lesbarer bei vielen Genen
  annotation_col = annotation_col,
  border_color = NA,
  fontsize = 10,
  scale = "row",
  main = paste0(
    "Overlap-Heatmap (LRT ‚à© Wald), n = ",
    nrow(mat_overlap),
    if (exists("n_heatmap")) paste0(" (max ", n_heatmap, ")") else ""
  )
)
```

```{r}
# ============================================================
# Pattern-Clustering der Wald‚à©LRT-Overlap-Gene mit DEGreport
# Ziel:
#   - sch√∂ne, interpretierbare Zeitverlaufs-Plots
#   - basierend auf robusten Genen (LRT ‚à© Wald)
#
# Voraussetzungen:
#   - overlap_genes_any_wald : Ensembl IDs (ohne Version)
#   - normalized_counts     : Matrix (Gene x Samples)
#   - meta                  : data.frame, rownames = samplename
# ============================================================

# ------------------------------------------------------------
# Helper: Ensembl-Versionen entfernen (ENSG... .16 -> ENSG...)
# ------------------------------------------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

# ------------------------------------------------------------
# 1) Metadaten f√ºr degPatterns vorbereiten
#    WICHTIG:
#    - metadata MUSS ein data.frame sein
#    - rownames(metadata) = Sample-Namen
# ------------------------------------------------------------
meta_deg <- meta |>
  tibble::rownames_to_column(var = "samplename") |>
  dplyr::select(samplename, timepoint) |>
  dplyr::mutate(condition = droplevels(timepoint)) |>
  as.data.frame()

rownames(meta_deg) <- meta_deg$samplename
meta_deg$samplename <- NULL

# Sanity-Check
stopifnot(all(rownames(meta_deg) %in% colnames(normalized_counts)))

# ------------------------------------------------------------
# 2) Matrix f√ºr Overlap-Gene bauen (Gene x Samples)
# ------------------------------------------------------------
mat_overlap <- normalized_counts[
  strip_ensembl_version(rownames(normalized_counts)) %in% overlap_genes_any_wald,
  ,
  drop = FALSE
]

# Rownames vereinheitlichen
rownames(mat_overlap) <- strip_ensembl_version(rownames(mat_overlap))

# Spaltenreihenfolge exakt an Metadaten anpassen
mat_overlap <- mat_overlap[, rownames(meta_deg), drop = FALSE]

# Optional: begrenzen, falls es zu viele Gene sind
n_max <- 500
if (nrow(mat_overlap) > n_max) {
  mat_overlap <- mat_overlap[seq_len(n_max), , drop = FALSE]
}

# ------------------------------------------------------------
# 3) degPatterns laufen lassen
# ------------------------------------------------------------
degPatterns(
  mat_overlap,
  metadata = meta_deg,
  time = "condition",
  minc = 30
)

# ============================================================
# Interpretation:
#   - Jeder Panel = ein Cluster / zeitliches Muster
#   - Punkte = einzelne Gene
#   - Linien = mittlerer Verlauf pro Cluster
#
# Ein gro√üer Teil der LRT‚à©Wald-Gene zeigt ein transient erh√∂htes Expressionsniveau bei V1 mit anschlie√üender R√ºckkehr zu Baseline bei V2
# ============================================================

```

```{r}

# ============================================================
# GO ORA (Over-Representation Analysis) ‚Äì DESeq2 Wald + LRT
# MIT CACHING (Summary-RDS) ‚Äì Copy-paste Block ans Ende deines Skripts
#
# Erwartete Objekte:
#   - res_V1_vs_A_tb, res_V2_vs_A_tb, res_V2_vs_V1_tb  (tibbles; gene, padj, log2FoldChange)
#   - res_lrt_tb (tibble; gene, padj) ODER res_lrt (DESeqResults)
#   - org.Hs.eg.db (Human)
#
# Output:
#   - ../../res/functional/ora_go/        (CSV + RDS + Dotplots)
#   - ../../res/cache/ora_go/             (Summary-Caches als RDS)
# ============================================================

# -----------------------------
# Helpers
# -----------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

.ensure_tbl_results <- function(x) {
  if (inherits(x, "DESeqResults")) {
    x |>
      as.data.frame() |>
      tibble::rownames_to_column(var = "gene") |>
      tibble::as_tibble()
  } else {
    tibble::as_tibble(x)
  }
}

.build_lists_for_ora <- function(res_tb, padj_cutoff = 0.05, lfc_col = "log2FoldChange") {
  res_tb <- .ensure_tbl_results(res_tb) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  universe <- unique(res_tb$ensembl_id)

  sig <- res_tb |>
    dplyr::filter(padj < padj_cutoff)

  sig_all <- unique(sig$ensembl_id)

  if (lfc_col %in% names(sig)) {
    sig_up <- unique(sig |> dplyr::filter(.data[[lfc_col]] > 0) |> dplyr::pull(ensembl_id))
    sig_down <- unique(sig |> dplyr::filter(.data[[lfc_col]] < 0) |> dplyr::pull(ensembl_id))
  } else {
    # LRT hat kein log2FoldChange
    sig_up <- character(0)
    sig_down <- character(0)
  }

  list(
    universe = universe,
    sig_all = sig_all,
    sig_up = sig_up,
    sig_down = sig_down
  )
}

.run_enrichgo <- function(sig_vec, universe_vec, ont = "BP",
                          p_adjust_method = "BH", q_cutoff = 0.05) {
  if (length(sig_vec) < 5) {
    return(NULL)
  }

  clusterProfiler::enrichGO(
    gene = sig_vec,
    universe = universe_vec,
    OrgDb = org.Hs.eg.db,
    keyType = "ENSEMBL",
    ont = ont,
    pAdjustMethod = p_adjust_method,
    qvalueCutoff = q_cutoff,
    readable = TRUE
  )
}

.save_enrichment <- function(enrich_obj, out_dir, stem,
                             make_plots = TRUE, show_category = 25) {
  if (is.null(enrich_obj)) {
    return(invisible(NULL))
  }

  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

  tab <- as.data.frame(enrich_obj)
  write.csv(tab, file.path(out_dir, paste0(stem, ".csv")), row.names = FALSE)
  saveRDS(enrich_obj, file.path(out_dir, paste0(stem, ".rds")))

  if (isTRUE(make_plots) && nrow(tab) > 0) {
    p <- enrichplot::dotplot(enrich_obj, showCategory = show_category) +
      ggplot2::ggtitle(stem) +
      ggplot2::theme_bw()

    ggplot2::ggsave(
      filename = file.path(out_dir, paste0(stem, "_dotplot.png")),
      plot = p,
      width = 9,
      height = 6,
      dpi = 200
    )
  }

  invisible(tab)
}

# -----------------------------
# Main: GO ORA f√ºr ein Set (Kontrast oder LRT) ‚Äì ohne Cache
# -----------------------------
run_go_ora_set <- function(res_obj,
                           set_label,
                           padj_cutoff = 0.05,
                           ontologies = c("BP", "MF", "CC"),
                           directions = c("all", "up", "down"),
                           out_dir = "../../res/functional/ora_go",
                           make_plots = TRUE) {
  lists <- .build_lists_for_ora(res_obj, padj_cutoff = padj_cutoff)

  summary_rows <- list()

  for (ont in ontologies) {
    for (dir in directions) {
      sig_vec <- switch(
        dir,
        all  = lists$sig_all,
        up   = lists$sig_up,
        down = lists$sig_down
      )

      # LRT: up/down ggf. leer -> skip
      if (length(sig_vec) == 0) next

      ego <- .run_enrichgo(sig_vec, lists$universe, ont = ont)

      stem <- paste0(
        "GO_", ont, "_", set_label, "_", dir,
        "_padj", format(padj_cutoff, nsmall = 2)
      )

      tab <- .save_enrichment(
        enrich_obj = ego,
        out_dir = out_dir,
        stem = stem,
        make_plots = make_plots,
        show_category = 25
      )

      if (is.null(tab) || nrow(tab) == 0) {
        summary_rows[[length(summary_rows) + 1]] <- tibble::tibble(
          set = set_label,
          ontology = ont,
          direction = dir,
          n_sig_genes = length(sig_vec),
          n_terms = 0L,
          top_term = NA_character_,
          top_term_padj = NA_real_
        )
      } else {
        summary_rows[[length(summary_rows) + 1]] <- tibble::tibble(
          set = set_label,
          ontology = ont,
          direction = dir,
          n_sig_genes = length(sig_vec),
          n_terms = nrow(tab),
          top_term = tab$Description[1],
          top_term_padj = tab$p.adjust[1]
        )
      }
    }
  }

  summary_tbl <- dplyr::bind_rows(summary_rows)

  dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
  write.csv(
    summary_tbl,
    file.path(
      out_dir,
      paste0("GO_ORA_summary_", set_label, "_padj", format(padj_cutoff, nsmall = 2), ".csv")
    ),
    row.names = FALSE
  )

  summary_tbl
}

# -----------------------------
# Caching Wrapper: l√§dt Summary-RDS, sonst rechnet + cach

```

```{r}
# ============================================================
# ORA mit optionalem Effektgr√∂√üen-Filter (lfc_min)
# - GO: enrichGO mit ENSEMBL
# - KEGG: enrichKEGG mit ENTREZ (ENSEMBL->ENTREZ Mapping)
#
# Copy/Paste Block: ans Ende deines Skripts (nach deinen DE-Results)
#
# Erwartete Objekte:
#   - res_V1_vs_A_tb, res_V2_vs_A_tb, res_V2_vs_V1_tb (tibble; gene, padj, log2FoldChange)
#   - res_lrt_tb (tibble; gene, padj) ODER res_lrt (DESeqResults)
#   - org.Hs.eg.db installiert (Human)
#
# Wichtig:
#   - lfc_min wird NUR angewandt, wenn log2FoldChange existiert (Wald).
#   - F√ºr LRT wird lfc_min ignoriert, directions = "all".
# ============================================================

suppressPackageStartupMessages({
  library(dplyr)
  library(tibble)
  library(clusterProfiler)
  library(enrichplot)
  library(org.Hs.eg.db)
  library(ggplot2)
  library(stringr)
})

# -----------------------------
# Settings (anpassbar)
# -----------------------------
if (!exists("padj_cutoff")) padj_cutoff <- 0.05

# Effektfilter (du kannst hier 0 / 0.5 / 1 setzen)
lfc_min_default <- 0.5

# Output-Dirs
go_out_dir   <- "../../res/functional/ora_go"
kegg_out_dir <- "../../res/functional/ora_kegg"
dir.create(go_out_dir,   recursive = TRUE, showWarnings = FALSE)
dir.create(kegg_out_dir, recursive = TRUE, showWarnings = FALSE)

# KEGG Organismus
kegg_organism <- "hsa"

# -----------------------------
# Helpers
# -----------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

.ensure_tbl_results <- function(x) {
  if (inherits(x, "DESeqResults")) {
    x |>
      as.data.frame() |>
      tibble::rownames_to_column(var = "gene") |>
      tibble::as_tibble()
  } else {
    tibble::as_tibble(x)
  }
}

# zentrales Filterverhalten f√ºr Wald (mit lfc_min)
.filter_sig_with_lfc <- function(res_tb,
                                 padj_cutoff = 0.05,
                                 direction = c("all", "up", "down"),
                                 lfc_min = 0,
                                 lfc_col = "log2FoldChange") {
  direction <- match.arg(direction)

  # base filtering
  sig <- res_tb |>
    dplyr::filter(!is.na(padj), padj < padj_cutoff)

  # wenn kein LFC vorhanden -> nur all sinnvoll (LRT)
  if (!lfc_col %in% names(sig)) {
    return(sig)
  }

  # apply effect-size filters
  if (direction == "all") {
    sig <- sig |>
      dplyr::filter(abs(.data[[lfc_col]]) >= lfc_min)
  } else if (direction == "up") {
    sig <- sig |>
      dplyr::filter(.data[[lfc_col]] >= lfc_min)
  } else if (direction == "down") {
    sig <- sig |>
      dplyr::filter(.data[[lfc_col]] <= -lfc_min)
  }

  sig
}

# -----------------------------
# GO ORA (ENSEMBL) with lfc_min
# -----------------------------
.build_go_lists <- function(res_obj, padj_cutoff = 0.05, direction = "all", lfc_min = 0) {
  res_tb <- .ensure_tbl_results(res_obj) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  universe <- unique(res_tb$ensembl_id)

  sig_tb <- .filter_sig_with_lfc(
    res_tb = res_tb,
    padj_cutoff = padj_cutoff,
    direction = direction,
    lfc_min = lfc_min
  )

  sig <- unique(sig_tb$ensembl_id)

  list(universe = universe, sig = sig, has_lfc = "log2FoldChange" %in% names(res_tb))
}

.run_enrichGO <- function(sig_vec, universe_vec, ont = "BP",
                          p_adjust_method = "BH", q_cutoff = 0.05) {
  if (length(sig_vec) < 5) return(NULL)

  clusterProfiler::enrichGO(
    gene          = sig_vec,
    universe      = universe_vec,
    OrgDb         = org.Hs.eg.db,
    keyType       = "ENSEMBL",
    ont           = ont,
    pAdjustMethod = p_adjust_method,
    qvalueCutoff  = q_cutoff,
    readable      = TRUE
  )
}

run_go_ora_set_lfc <- function(res_obj,
                               set_label,
                               padj_cutoff = 0.05,
                               lfc_min = 0,
                               ontologies = c("BP", "MF", "CC"),
                               directions = c("all", "up", "down"),
                               out_dir = go_out_dir) {
  res_tb <- .ensure_tbl_results(res_obj)
  has_lfc <- "log2FoldChange" %in% names(res_tb)

  # LRT: nur "all"
  if (!has_lfc) directions <- intersect(directions, "all")

  summary_rows <- list()

  for (ont in ontologies) {
    for (dir in directions) {
      lists <- .build_go_lists(
        res_obj = res_obj,
        padj_cutoff = padj_cutoff,
        direction = dir,
        lfc_min = lfc_min
      )

      ego <- .run_enrichGO(lists$sig, lists$universe, ont = ont)

      stem <- paste0(
        "GO_", ont, "_", set_label, "_", dir,
        "_padj", format(padj_cutoff, nsmall = 2),
        if (has_lfc) paste0("_lfc", format(lfc_min, nsmall = 2)) else ""
      )

      # save
      if (!is.null(ego)) {
        tab <- as.data.frame(ego)
        write.csv(tab, file.path(out_dir, paste0(stem, ".csv")), row.names = FALSE)
        saveRDS(ego, file.path(out_dir, paste0(stem, ".rds")))
        n_terms <- nrow(tab)
        top_term <- if (n_terms > 0) tab$Description[1] else NA_character_
        top_padj <- if (n_terms > 0) tab$p.adjust[1] else NA_real_
      } else {
        n_terms <- 0L
        top_term <- NA_character_
        top_padj <- NA_real_
      }

      summary_rows[[length(summary_rows) + 1]] <- tibble::tibble(
        set = set_label,
        ontology = ont,
        direction = dir,
        padj_cutoff = padj_cutoff,
        lfc_min = if (has_lfc) lfc_min else NA_real_,
        n_sig_genes = length(lists$sig),
        n_terms = n_terms,
        top_term = top_term,
        top_term_padj = top_padj
      )
    }
  }

  summary_tbl <- dplyr::bind_rows(summary_rows)

  write.csv(
    summary_tbl,
    file.path(out_dir, paste0(
      "GO_ORA_summary_", set_label,
      "_padj", format(padj_cutoff, nsmall = 2),
      if (has_lfc) paste0("_lfc", format(lfc_min, nsmall = 2)) else "",
      ".csv"
    )),
    row.names = FALSE
  )

  summary_tbl
}

# -----------------------------
# KEGG ORA (ENTREZ) with lfc_min
# -----------------------------
.map_ens_to_entrez <- function(ens_vec) {
  ens_vec <- unique(ens_vec[!is.na(ens_vec)])
  if (length(ens_vec) == 0) return(tibble::tibble(ENSEMBL = character(), ENTREZID = character()))

  suppressMessages(
    clusterProfiler::bitr(
      ens_vec,
      fromType = "ENSEMBL",
      toType   = "ENTREZID",
      OrgDb    = org.Hs.eg.db
    )
  ) |>
    tibble::as_tibble()
}

.build_kegg_lists <- function(res_obj, padj_cutoff = 0.05, direction = "all", lfc_min = 0) {
  res_tb <- .ensure_tbl_results(res_obj) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  # Universe ENSEMBL -> ENTREZ
  universe_ens <- unique(res_tb$ensembl_id)
  map_univ <- .map_ens_to_entrez(universe_ens)
  universe_entrez <- unique(map_univ$ENTREZID)

  # Sig genes with lfc_min
  sig_tb <- .filter_sig_with_lfc(
    res_tb = res_tb,
    padj_cutoff = padj_cutoff,
    direction = direction,
    lfc_min = lfc_min
  )

  sig_ens <- unique(sig_tb$ensembl_id)
  map_sig <- .map_ens_to_entrez(sig_ens)
  sig_entrez <- unique(map_sig$ENTREZID)

  list(universe = universe_entrez, sig = sig_entrez, has_lfc = "log2FoldChange" %in% names(res_tb))
}

.run_enrichKEGG <- function(sig_entrez, universe_entrez, organism = "hsa",
                            p_adjust_method = "BH",
                            pvalue_cutoff = 0.05,
                            qvalue_cutoff = 0.05) {
  if (length(sig_entrez) < 5) return(NULL)

  suppressMessages(
    clusterProfiler::enrichKEGG(
      gene          = sig_entrez,
      universe      = universe_entrez,
      organism      = organism,
      pAdjustMethod = p_adjust_method,
      pvalueCutoff  = pvalue_cutoff,
      qvalueCutoff  = qvalue_cutoff
    )
  )
}

run_kegg_ora_set_lfc <- function(res_obj,
                                 set_label,
                                 padj_cutoff = 0.05,
                                 lfc_min = 0,
                                 directions = c("all", "up", "down"),
                                 out_dir = kegg_out_dir,
                                 organism = kegg_organism) {
  res_tb <- .ensure_tbl_results(res_obj)
  has_lfc <- "log2FoldChange" %in% names(res_tb)

  # LRT: nur "all"
  if (!has_lfc) directions <- intersect(directions, "all")

  summary_rows <- list()

  for (dir in directions) {
    lists <- .build_kegg_lists(
      res_obj = res_obj,
      padj_cutoff = padj_cutoff,
      direction = dir,
      lfc_min = lfc_min
    )

    ek <- .run_enrichKEGG(lists$sig, lists$universe, organism = organism)

    stem <- paste0(
      "KEGG_", set_label, "_", dir,
      "_padj", format(padj_cutoff, nsmall = 2),
      if (has_lfc) paste0("_lfc", format(lfc_min, nsmall = 2)) else ""
    )

    if (!is.null(ek)) {
      tab <- as.data.frame(ek)
      write.csv(tab, file.path(out_dir, paste0(stem, ".csv")), row.names = FALSE)
      saveRDS(ek, file.path(out_dir, paste0(stem, ".rds")))
      n_terms <- nrow(tab)
      top_path <- if (n_terms > 0) tab$Description[1] else NA_character_
      top_padj <- if (n_terms > 0) tab$p.adjust[1] else NA_real_
    } else {
      n_terms <- 0L
      top_path <- NA_character_
      top_padj <- NA_real_
    }

    summary_rows[[length(summary_rows) + 1]] <- tibble::tibble(
      set = set_label,
      direction = dir,
      padj_cutoff = padj_cutoff,
      lfc_min = if (has_lfc) lfc_min else NA_real_,
      n_sig_genes_entrez = length(lists$sig),
      n_terms = n_terms,
      top_pathway = top_path,
      top_padj = top_padj
    )
  }

  summary_tbl <- dplyr::bind_rows(summary_rows)

  write.csv(
    summary_tbl,
    file.path(out_dir, paste0(
      "KEGG_ORA_summary_", set_label,
      "_padj", format(padj_cutoff, nsmall = 2),
      if (has_lfc) paste0("_lfc", format(lfc_min, nsmall = 2)) else "",
      ".csv"
    )),
    row.names = FALSE
  )

  summary_tbl
}

# ============================================================
# RUN EXAMPLE: lfc_min = 0.5 (empfohlen)
# ============================================================

lfc_min <- lfc_min_default  # z.B. 0, 0.5, 1

# --- GO ---
go_v1_a  <- run_go_ora_set_lfc(res_V1_vs_A_tb,  "Wald_V1_vs_A",  padj_cutoff, lfc_min)
go_v2_a  <- run_go_ora_set_lfc(res_V2_vs_A_tb,  "Wald_V2_vs_A",  padj_cutoff, lfc_min)
go_v2_v1 <- run_go_ora_set_lfc(res_V2_vs_V1_tb, "Wald_V2_vs_V1", padj_cutoff, lfc_min)

lrt_input <- if (exists("res_lrt_tb")) res_lrt_tb else res_lrt
go_lrt <- run_go_ora_set_lfc(lrt_input, "LRT_timepoint", padj_cutoff, lfc_min = 0, directions = "all")

go_all <- dplyr::bind_rows(go_v1_a, go_v2_a, go_v2_v1, go_lrt)
write.csv(
  go_all,
  file.path(go_out_dir, paste0("GO_ORA_summary_ALL_padj", format(padj_cutoff, nsmall = 2),
                               "_lfc", format(lfc_min, nsmall = 2), ".csv")),
  row.names = FALSE
)

# --- KEGG ---
kegg_v1_a  <- run_kegg_ora_set_lfc(res_V1_vs_A_tb,  "Wald_V1_vs_A",  padj_cutoff, lfc_min)
kegg_v2_a  <- run_kegg_ora_set_lfc(res_V2_vs_A_tb,  "Wald_V2_vs_A",  padj_cutoff, lfc_min)
kegg_v2_v1 <- run_kegg_ora_set_lfc(res_V2_vs_V1_tb, "Wald_V2_vs_V1", padj_cutoff, lfc_min)

kegg_lrt <- run_kegg_ora_set_lfc(lrt_input, "LRT_timepoint", padj_cutoff, lfc_min = 0, directions = "all")

kegg_all <- dplyr::bind_rows(kegg_v1_a, kegg_v2_a, kegg_v2_v1, kegg_lrt)
write.csv(
  kegg_all,
  file.path(kegg_out_dir, paste0("KEGG_ORA_summary_ALL_padj", format(padj_cutoff, nsmall = 2),
                                 "_lfc", format(lfc_min, nsmall = 2), ".csv")),
  row.names = FALSE
)

go_all
kegg_all

```

```{r}
# ============================================================
# GO + KEGG ORA PLOTS (RDS-first, kein Neuberechnen der ORA!)
#   - dotplot (lesbar: wrap + dynamische H√∂he)
#   - emapplot (pairwise_termsim wird als *_termsim.rds gecached)
#   - cnetplot (nur wenn log2FC existiert UND foldChange geliefert wird)
#
# WICHTIG:
#   - Dieser Block rechnet KEINE enrichGO/enrichKEGG neu.
#   - Er l√§dt nur vorhandene *.rds aus go_out_dir / kegg_out_dir.
#
# Erwartete Objekte aus deinem Skript:
#   - go_out_dir, kegg_out_dir (wie im ORA-Block)
#   - padj_cutoff
#   - lfc_min (wenn du mit lfc_min gerechnet hast; sonst 0 setzen)
#   - res_V1_vs_A_tb, res_V2_vs_A_tb, res_V2_vs_V1_tb (f√ºr foldChange-Vektor)
#   - res_lrt_tb ODER res_lrt (nur f√ºrs "has_lfc" Erkennen; FC bleibt NULL)
#
# Output:
#   - <go_out_dir>/plots/
#   - <kegg_out_dir>/plots/
# ============================================================
# -----------------------------
# Defaults falls nicht gesetzt
# -----------------------------
if (!exists("padj_cutoff")) padj_cutoff <- 0.05
if (!exists("lfc_min")) lfc_min <- 0.5   # WICHTIG: auf denselben Wert wie beim ORA-Lauf setzen!
if (!exists("go_out_dir")) go_out_dir <- "../../res/functional/ora_go"
if (!exists("kegg_out_dir")) kegg_out_dir <- "../../res/functional/ora_kegg"

go_plots_dir <- file.path(go_out_dir, "plots")
kegg_plots_dir <- file.path(kegg_out_dir, "plots")
dir.create(go_plots_dir, recursive = TRUE, showWarnings = FALSE)
dir.create(kegg_plots_dir, recursive = TRUE, showWarnings = FALSE)

# Plot-Defaults (anpassen)
show_dot  <- 30
show_emap <- 30
show_cnet <- 5

# GO Ontologies (meist BP im Main, MF/CC optional)
go_ontologies <- c("BP")  # z.B. c("BP","MF","CC")

# -----------------------------
# Helpers
# -----------------------------
strip_ensembl_version <- function(x) sub("\\..*$", "", x)

.ensure_tbl_results <- function(x) {
  if (inherits(x, "DESeqResults")) {
    x |>
      as.data.frame() |>
      tibble::rownames_to_column(var = "gene") |>
      tibble::as_tibble()
  } else {
    tibble::as_tibble(x)
  }
}

# FoldChange Vektor f√ºr GO (names=ENSEMBL ohne Version)
.make_fc_go <- function(res_obj, padj_cutoff, direction, lfc_min = 0) {
  res_tb <- .ensure_tbl_results(res_obj) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  if (!"log2FoldChange" %in% names(res_tb)) return(NULL)

  sig <- res_tb |>
    dplyr::filter(padj < padj_cutoff)

  if (direction == "all") {
    sig <- sig |> dplyr::filter(abs(log2FoldChange) >= lfc_min)
  } else if (direction == "up") {
    sig <- sig |> dplyr::filter(log2FoldChange >= lfc_min)
  } else if (direction == "down") {
    sig <- sig |> dplyr::filter(log2FoldChange <= -lfc_min)
  }

  fc <- sig$log2FoldChange
  names(fc) <- sig$ensembl_id
  fc <- fc[!duplicated(names(fc))]
  fc
}

# FoldChange Vektor f√ºr KEGG (names=ENTREZID)
.make_fc_kegg <- function(res_obj, padj_cutoff, direction, lfc_min = 0) {
  res_tb <- .ensure_tbl_results(res_obj) |>
    dplyr::filter(!is.na(padj)) |>
    dplyr::mutate(ensembl_id = strip_ensembl_version(gene))

  if (!"log2FoldChange" %in% names(res_tb)) return(NULL)

  sig <- res_tb |>
    dplyr::filter(padj < padj_cutoff)

  if (direction == "all") {
    sig <- sig |> dplyr::filter(abs(log2FoldChange) >= lfc_min)
  } else if (direction == "up") {
    sig <- sig |> dplyr::filter(log2FoldChange >= lfc_min)
  } else if (direction == "down") {
    sig <- sig |> dplyr::filter(log2FoldChange <= -lfc_min)
  }

  # Map ENS -> ENTREZ (f√ºr cnetplot bei KEGG)
  map_sig <- suppressMessages(
    clusterProfiler::bitr(
      unique(sig$ensembl_id),
      fromType = "ENSEMBL",
      toType   = "ENTREZID",
      OrgDb    = org.Hs.eg.db
    )
  )

  sig2 <- sig |>
    dplyr::left_join(map_sig, by = c("ensembl_id" = "ENSEMBL")) |>
    dplyr::filter(!is.na(ENTREZID))

  fc <- sig2$log2FoldChange
  names(fc) <- sig2$ENTREZID
  fc <- fc[!duplicated(names(fc))]
  fc
}

# RDS loader (Enrichment Objekt)
.load_rds_enrich <- function(rds_path) {
  if (!file.exists(rds_path)) return(NULL)
  obj <- readRDS(rds_path)
  tab <- tryCatch(as.data.frame(obj), error = function(e) NULL)
  if (is.null(tab) || nrow(tab) == 0) return(NULL)
  obj
}

# pairwise_termsim cache
.get_termsim_cached <- function(enrich_obj, cache_path) {
  if (file.exists(cache_path)) {
    return(readRDS(cache_path))
  }
  ts <- tryCatch(enrichplot::pairwise_termsim(enrich_obj), error = function(e) NULL)
  if (!is.null(ts)) saveRDS(ts, cache_path)
  ts
}

# dotplot helper (lesbar, dynamische H√∂he)
.make_dotplot <- function(enrich_obj, title, show_dot = 30) {
  tab <- as.data.frame(enrich_obj)
  show_dot_local <- min(show_dot, nrow(tab))
  height <- max(7, min(18, 0.28 * show_dot_local))

  p <- suppressWarnings(
    enrichplot::dotplot(enrich_obj, showCategory = show_dot_local) +
      ggplot2::ggtitle(title) +
      ggplot2::scale_y_discrete(labels = \(x) stringr::str_wrap(x, width = 38)) +
      ggplot2::theme_bw() +
      ggplot2::theme(axis.text.y = ggplot2::element_text(size = 9))
  )

  list(plot = p, height = height)
}

# safe ggsave
.save_plot <- function(p, filename, width = 11, height = 7, dpi = 200) {
  ggplot2::ggsave(filename = filename, plot = p, width = width, height = height, dpi = dpi)
}

# -----------------------------
# GO Plot Runner (RDS-first)
# -----------------------------
plot_go_from_rds <- function(set_label,
                             res_obj_for_fc = NULL,
                             directions = c("all", "up", "down"),
                             ontologies = c("BP"),
                             out_dir = go_out_dir,
                             plots_dir = go_plots_dir,
                             padj_cutoff = 0.05,
                             lfc_min = 0) {
  has_lfc <- !is.null(res_obj_for_fc) && ("log2FoldChange" %in% names(.ensure_tbl_results(res_obj_for_fc)))
  if (!has_lfc) directions <- intersect(directions, "all")

  for (ont in ontologies) {
    for (dir in directions) {
      stem <- paste0(
        "GO_", ont, "_", set_label, "_", dir,
        "_padj", format(padj_cutoff, nsmall = 2),
        if (has_lfc) paste0("_lfc", format(lfc_min, nsmall = 2)) else ""
      )
      rds_path <- file.path(out_dir, paste0(stem, ".rds"))
      ego <- .load_rds_enrich(rds_path)
      if (is.null(ego)) {
        message("GO skip (kein RDS/0 Terms): ", stem)
        next
      }

      # 1) dotplot
      dp <- .make_dotplot(ego, title = paste0(stem, " ‚Äì dotplot"), show_dot = show_dot)
      .save_plot(dp$plot, file.path(plots_dir, paste0(stem, "_dotplot.png")),
                 width = 11, height = dp$height)

      # 2) emapplot (cached termsim)
      ts_path <- file.path(out_dir, paste0(stem, "_termsim.rds"))
      ego_ts <- .get_termsim_cached(ego, ts_path)
      if (!is.null(ego_ts)) {
        p_emap <- tryCatch(
          enrichplot::emapplot(ego_ts, showCategory = show_emap) +
            ggplot2::ggtitle(paste0(stem, " ‚Äì emapplot")) +
            ggplot2::theme_void(),
          error = function(e) NULL
        )
        if (!is.null(p_emap)) {
          .save_plot(p_emap, file.path(plots_dir, paste0(stem, "_emapplot.png")),
                     width = 12, height = 9)
        }
      }

      # 3) cnetplot (nur Wald; foldChange)
      if (has_lfc) {
        fc <- .make_fc_go(res_obj_for_fc, padj_cutoff = padj_cutoff, direction = dir, lfc_min = lfc_min)
        if (!is.null(fc) && length(fc) >= 5 && !is.null(ego_ts)) {
          p_cnet <- tryCatch(
            enrichplot::cnetplot(
              ego_ts,
              showCategory = show_cnet,
              foldChange = fc,
              node_label = "category"
            ) +
              ggplot2::ggtitle(paste0(stem, " ‚Äì cnetplot")) +
              ggplot2::theme_void(),
            error = function(e) NULL
          )
          if (!is.null(p_cnet)) {
            .save_plot(p_cnet, file.path(plots_dir, paste0(stem, "_cnetplot.png")),
                       width = 13, height = 9)
          }
        } else {
          message("GO cnet skip (kein FC/termsim): ", stem)
        }
      }
    }
  }

  invisible(TRUE)
}

# -----------------------------
# KEGG Plot Runner (RDS-first)
# -----------------------------
plot_kegg_from_rds <- function(set_label,
                               res_obj_for_fc = NULL,
                               directions = c("all", "up", "down"),
                               out_dir = kegg_out_dir,
                               plots_dir = kegg_plots_dir,
                               padj_cutoff = 0.05,
                               lfc_min = 0) {
  has_lfc <- !is.null(res_obj_for_fc) && ("log2FoldChange" %in% names(.ensure_tbl_results(res_obj_for_fc)))
  if (!has_lfc) directions <- intersect(directions, "all")

  for (dir in directions) {
    stem <- paste0(
      "KEGG_", set_label, "_", dir,
      "_padj", format(padj_cutoff, nsmall = 2),
      if (has_lfc) paste0("_lfc", format(lfc_min, nsmall = 2)) else ""
    )
    rds_path <- file.path(out_dir, paste0(stem, ".rds"))
    ek <- .load_rds_enrich(rds_path)
    if (is.null(ek)) {
      message("KEGG skip (kein RDS/0 Terms): ", stem)
      next
    }

    # 1) dotplot
    dp <- .make_dotplot(ek, title = paste0(stem, " ‚Äì dotplot"), show_dot = show_dot)
    .save_plot(dp$plot, file.path(plots_dir, paste0(stem, "_dotplot.png")),
               width = 11, height = dp$height)

# --- helper: check if emapplot is safe ---------------------------------
.is_emap_safe <- function(x, min_terms = 3) {
  if (is.null(x)) return(FALSE)

  df <- tryCatch(as.data.frame(x), error = function(e) NULL)
  if (is.null(df) || nrow(df) < min_terms) return(FALSE)

  # pairwise_termsim() stores similarity in @termsim for enrichResult objects
  ts <- tryCatch(x@termsim, error = function(e) NULL)
  if (is.null(ts)) return(FALSE)

  # needs at least some finite similarity off-diagonal to make edges
  ts2 <- as.matrix(ts)
  if (nrow(ts2) < min_terms || ncol(ts2) < min_terms) return(FALSE)

  # remove diagonal, check for any finite > 0 similarities
  diag(ts2) <- NA_real_
  ok <- any(is.finite(ts2) & ts2 > 0, na.rm = TRUE)
  ok
}

# 2) emapplot (cached termsim) ‚Äì ROBUST
ts_path <- file.path(out_dir, paste0(stem, "_termsim.rds"))
ek_ts <- .get_termsim_cached(ek, ts_path)

if (.is_emap_safe(ek_ts, min_terms = 3)) {
  p_emap <- tryCatch(
    enrichplot::emapplot(
      ek_ts,
      showCategory = min(show_emap, nrow(as.data.frame(ek_ts))),
      layout = "nicely"
    ) +
      ggplot2::ggtitle(paste0(stem, " ‚Äì emapplot")) +
      ggplot2::theme_void(),
    error = function(e) {
      message("Skip KEGG emapplot (", stem, "): ", conditionMessage(e))
      NULL
    }
  )

  if (!is.null(p_emap)) {
    .save_plot(
      p_emap,
      file.path(plots_dir, paste0(stem, "_emapplot.png")),
      width = 12,
      height = 9
    )
  }
} else {
  message("Skip KEGG emapplot (zu wenige/keine Kanten): ", stem)
}


    # 3) cnetplot (nur Wald; foldChange)
    if (has_lfc) {
      fc <- .make_fc_kegg(res_obj_for_fc, padj_cutoff = padj_cutoff, direction = dir, lfc_min = lfc_min)
      if (!is.null(fc) && length(fc) >= 5 && !is.null(ek_ts)) {
        p_cnet <- tryCatch(
          enrichplot::cnetplot(
            ek_ts,
            showCategory = show_cnet,
            foldChange = fc,
            node_label = "category"
          ) +
            ggplot2::ggtitle(paste0(stem, " ‚Äì cnetplot")) +
            ggplot2::theme_void(),
          error = function(e) NULL
        )
        if (!is.null(p_cnet)) {
          .save_plot(p_cnet, file.path(plots_dir, paste0(stem, "_cnetplot.png")),
                     width = 13, height = 9)
        }
      } else {
        message("KEGG cnet skip (kein FC/termsim): ", stem)
      }
    }
  }

  invisible(TRUE)
}

# ============================================================
# RUN: alle Kontraste (GO + KEGG) aus RDS plotten
# ============================================================

# Wald
plot_go_from_rds("Wald_V1_vs_A",  res_obj_for_fc = res_V1_vs_A_tb,
                 directions = c("all","up","down"), ontologies = go_ontologies,
                 padj_cutoff = padj_cutoff, lfc_min = lfc_min)

plot_go_from_rds("Wald_V2_vs_A",  res_obj_for_fc = res_V2_vs_A_tb,
                 directions = c("all","up","down"), ontologies = go_ontologies,
                 padj_cutoff = padj_cutoff, lfc_min = lfc_min)

plot_go_from_rds("Wald_V2_vs_V1", res_obj_for_fc = res_V2_vs_V1_tb,
                 directions = c("all","up","down"), ontologies = go_ontologies,
                 padj_cutoff = padj_cutoff, lfc_min = lfc_min)

# LRT (nur all; kein FC)
lrt_input <- if (exists("res_lrt_tb")) res_lrt_tb else res_lrt
plot_go_from_rds("LRT_timepoint", res_obj_for_fc = NULL,
                 directions = c("all"), ontologies = go_ontologies,
                 padj_cutoff = padj_cutoff, lfc_min = 0)

# KEGG
plot_kegg_from_rds("Wald_V1_vs_A",  res_obj_for_fc = res_V1_vs_A_tb,
                   directions = c("all","up","down"),
                   padj_cutoff = padj_cutoff, lfc_min = lfc_min)

plot_kegg_from_rds("Wald_V2_vs_A",  res_obj_for_fc = res_V2_vs_A_tb,
                   directions = c("all","up","down"),
                   padj_cutoff = padj_cutoff, lfc_min = lfc_min)

plot_kegg_from_rds("Wald_V2_vs_V1", res_obj_for_fc = res_V2_vs_V1_tb,
                   directions = c("all","up","down"),
                   padj_cutoff = padj_cutoff, lfc_min = lfc_min)

plot_kegg_from_rds("LRT_timepoint", res_obj_for_fc = NULL,
                   directions = c("all"),
                   padj_cutoff = padj_cutoff, lfc_min = 0)

message("Fertig. GO Plots:   ", normalizePath(go_plots_dir))
message("Fertig. KEGG Plots: ", normalizePath(kegg_plots_dir))

```

```{r}
#| label: fig-publication-go-kegg
#| fig-width: 20
#| fig-height: 14
# ============================================================
# PUBLIKATIONSREIFE MULTI-PANEL FIGURE: GO + KEGG + Heatmap
#
# Verbesserungen gegen√ºber vorheriger Version:
#   - Einheitliche Vergleiche: V1 vs A und V2 vs V1 f√ºr GO UND KEGG
#   - Einheitliche p.adjust Farbskala √ºber alle Panels
#   - Bessere Panel-Labels (A-F gro√ü und fett)
#   - Optimiertes Breitenverh√§ltnis (Dotplots : Heatmap)
#   - Weniger Kategorien (8) f√ºr bessere Lesbarkeit
#   - Heatmap mit Pathway-Annotation (row_annotation)
#   - Verbesserte Term-Label-Formatierung (str_wrap)
#   - Visuelle Trennung GO / KEGG durch Spacing
# ============================================================

suppressPackageStartupMessages({

  library(ggplot2)
  library(patchwork)
  library(enrichplot)
  library(pheatmap)
  library(RColorBrewer)
  library(stringr)
  library(dplyr)
  library(tibble)
  library(grid)
})

# -----------------------------
# 0) Settings
# -----------------------------
padj_cutoff <- if (exists("padj_cutoff")) padj_cutoff else 0.05
lfc_min     <- if (exists("lfc_min")) lfc_min else 0.5

go_out_dir   <- if (exists("go_out_dir")) go_out_dir else "../../res/functional/ora_go"
kegg_out_dir <- if (exists("kegg_out_dir")) kegg_out_dir else "../../res/functional/ora_kegg"

fig_out_dir  <- "../../res/figures"
dir.create(fig_out_dir, recursive = TRUE, showWarnings = FALSE)

# Plot-Parameter
n_category    <- 8        # Anzahl GO/KEGG Terms pro Panel
padj_limits   <- c(1e-12, 0.05)  # Einheitliche Farbskala
dot_size_range <- c(2, 8)        # Punktgr√∂√üen
term_wrap_width <- 35            # Zeilenumbruch f√ºr Term-Labels

# Titel
title_main    <- "TAVI-associated immune trajectory (A ‚Üí V1 ‚Üí V2)"
subtitle_main <- paste0("GO/KEGG ORA (padj < ", padj_cutoff, ", |log2FC| ‚â• ", lfc_min, ")")

# -----------------------------
# 1) Helper-Funktionen
# -----------------------------
fmt2 <- function(x) format(x, nsmall = 2)

stem_go <- function(ont, set_label, dir, padj_cutoff, lfc_min) {

  paste0("GO_", ont, "_", set_label, "_", dir, "_padj", fmt2(padj_cutoff), "_lfc", fmt2(lfc_min))
}

stem_kegg <- function(set_label, dir, padj_cutoff, lfc_min) {
  paste0("KEGG_", set_label, "_", dir, "_padj", fmt2(padj_cutoff), "_lfc", fmt2(lfc_min))
}

safe_read_rds <- function(path) {
  if (!file.exists(path)) return(NULL)
  obj <- tryCatch(readRDS(path), error = function(e) NULL)
  df  <- tryCatch(as.data.frame(obj), error = function(e) NULL)
  if (is.null(df) || nrow(df) == 0) return(NULL)
  obj
}

# Verbesserter Dotplot mit einheitlicher Skala und besserem Wrapping
pub_dotplot <- function(enrich_obj, title, n_cat = n_category,
                        padj_lim = padj_limits, wrap_width = term_wrap_width) {

  # Fallback f√ºr leere/fehlende Daten

  if (is.null(enrich_obj)) {
    return(
      ggplot() +
        annotate("text", x = 0.5, y = 0.5, label = "No enriched terms",
                 size = 4, color = "grey50") +
        theme_void() +
        ggtitle(title) +
        theme(plot.title = element_text(size = 11, face = "bold", hjust = 0.5))
    )
  }

  df <- as.data.frame(enrich_obj)
  if (nrow(df) == 0) {
    return(
      ggplot() +
        annotate("text", x = 0.5, y = 0.5, label = "No enriched terms",
                 size = 4, color = "grey50") +
        theme_void() +
        ggtitle(title) +
        theme(plot.title = element_text(size = 11, face = "bold", hjust = 0.5))
    )
  }

  # Top n_cat Terms

  df_top <- df %>%
    slice_head(n = n_cat) %>%
    mutate(
      Description = str_wrap(Description, width = wrap_width),
      Description = factor(Description, levels = rev(Description)),
      GeneRatio_num = sapply(strsplit(GeneRatio, "/"), function(x) as.numeric(x[1]) / as.numeric(x[2]))
    )

  ggplot(df_top, aes(x = GeneRatio_num, y = Description)) +
    geom_point(aes(size = Count, color = p.adjust)) +
    scale_color_gradient(
      low = "#d73027", high = "#4575b4",
      trans = "log10",
      limits = padj_lim,
      oob = scales::squish,
      name = "p.adjust"
    ) +
    scale_size_continuous(range = dot_size_range, name = "Count") +
    labs(x = "Gene Ratio", y = NULL, title = title) +
    theme_bw(base_size = 10) +
    theme(
      plot.title = element_text(size = 11, face = "bold"),
      axis.text.y = element_text(size = 9),
      axis.text.x = element_text(size = 8),
      legend.position = "right",
      legend.key.size = unit(0.4, "cm"),
      legend.title = element_text(size = 8),
      legend.text = element_text(size = 7),
      panel.grid.minor = element_blank()
    )
}

# Gene aus ORA-Ergebnissen extrahieren
get_top_genes_from_enrich <- function(enrich_obj, n_terms = 3) {
  if (is.null(enrich_obj)) return(list(genes = character(), terms = character()))
  df <- tryCatch(as.data.frame(enrich_obj), error = function(e) NULL)
  if (is.null(df) || nrow(df) == 0) return(list(genes = character(), terms = character()))

  df_top <- df %>% slice_head(n = min(n_terms, nrow(df)))

  genes <- unlist(strsplit(df_top$geneID, "/", fixed = TRUE), use.names = FALSE)
  genes <- unique(genes[!is.na(genes) & genes != ""])
  terms <- df_top$Description

  list(genes = genes, terms = terms)
}

# -----------------------------
# 2) ORA RDS laden - EINHEITLICHE Vergleiche: V1 vs A + V2 vs V1
# -----------------------------
# GO BP
go_v1a_up    <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("BP", "Wald_V1_vs_A", "up", padj_cutoff, lfc_min), ".rds")))
go_v1a_down  <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("BP", "Wald_V1_vs_A", "down", padj_cutoff, lfc_min), ".rds")))
go_v2v1_up   <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("BP", "Wald_V2_vs_V1", "up", padj_cutoff, lfc_min), ".rds")))
go_v2v1_down <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("BP", "Wald_V2_vs_V1", "down", padj_cutoff, lfc_min), ".rds")))

# KEGG - GLEICHE Vergleiche wie GO
kegg_v1a_up    <- safe_read_rds(file.path(kegg_out_dir, paste0(stem_kegg("Wald_V1_vs_A", "up", padj_cutoff, lfc_min), ".rds")))
kegg_v1a_down  <- safe_read_rds(file.path(kegg_out_dir, paste0(stem_kegg("Wald_V1_vs_A", "down", padj_cutoff, lfc_min), ".rds")))
kegg_v2v1_up   <- safe_read_rds(file.path(kegg_out_dir, paste0(stem_kegg("Wald_V2_vs_V1", "up", padj_cutoff, lfc_min), ".rds")))
kegg_v2v1_down <- safe_read_rds(file.path(kegg_out_dir, paste0(stem_kegg("Wald_V2_vs_V1", "down", padj_cutoff, lfc_min), ".rds")))

# -----------------------------
# 3) Dotplots erstellen
# -----------------------------
p_go_v1a_up    <- pub_dotplot(go_v1a_up,    "GO BP: V1 vs A (UP)")
p_go_v1a_down  <- pub_dotplot(go_v1a_down,  "GO BP: V1 vs A (DOWN)")
p_go_v2v1_up   <- pub_dotplot(go_v2v1_up,   "GO BP: V2 vs V1 (UP)")
p_go_v2v1_down <- pub_dotplot(go_v2v1_down, "GO BP: V2 vs V1 (DOWN)")

p_kegg_v1a_up    <- pub_dotplot(kegg_v1a_up,    "KEGG: V1 vs A (UP)")
p_kegg_v1a_down  <- pub_dotplot(kegg_v1a_down,  "KEGG: V1 vs A (DOWN)")
p_kegg_v2v1_up   <- pub_dotplot(kegg_v2v1_up,   "KEGG: V2 vs V1 (UP)")
p_kegg_v2v1_down <- pub_dotplot(kegg_v2v1_down, "KEGG: V2 vs V1 (DOWN)")

# -----------------------------
# 4) Heatmap mit Pathway-Annotation
# -----------------------------
heat_panel <- NULL

if (!exists("trans") || !exists("meta")) {
  warning("Heatmap: 'trans' oder 'meta' nicht gefunden.")
} else {
  trans_mat <- SummarizedExperiment::assay(trans)

  # Rownames der Matrix: ENSEMBL IDs (ggf. mit Version)
  # Wir strippen die Version f√ºr konsistentes Matching
  trans_rownames_clean <- sub("\\..*$", "", rownames(trans_mat))

  # Gene aus verschiedenen ORA-Quellen mit Pathway-Zuordnung
  # Mehr Terms extrahieren f√ºr robustere Genauswahl
  genes_go_v1a_up    <- get_top_genes_from_enrich(go_v1a_up, n_terms = 3)
  genes_go_v1a_down  <- get_top_genes_from_enrich(go_v1a_down, n_terms = 3)
  genes_go_v2v1_up   <- get_top_genes_from_enrich(go_v2v1_up, n_terms = 3)
  genes_go_v2v1_down <- get_top_genes_from_enrich(go_v2v1_down, n_terms = 3)
  genes_kegg_v1a_up  <- get_top_genes_from_enrich(kegg_v1a_up, n_terms = 2)
  genes_kegg_v1a_down<- get_top_genes_from_enrich(kegg_v1a_down, n_terms = 2)
  genes_kegg_v2v1_up <- get_top_genes_from_enrich(kegg_v2v1_up, n_terms = 2)
  genes_kegg_v2v1_down <- get_top_genes_from_enrich(kegg_v2v1_down, n_terms = 2)

  # Pathway-Annotation aufbauen
  pathway_anno <- dplyr::bind_rows(
    tibble(gene = genes_go_v1a_up$genes, pathway = "GO: V1/A UP"),
    tibble(gene = genes_go_v1a_down$genes, pathway = "GO: V1/A DOWN"),
    tibble(gene = genes_go_v2v1_up$genes, pathway = "GO: V2/V1 UP"),
    tibble(gene = genes_go_v2v1_down$genes, pathway = "GO: V2/V1 DOWN"),
    tibble(gene = genes_kegg_v1a_up$genes, pathway = "KEGG: V1/A UP"),
    tibble(gene = genes_kegg_v1a_down$genes, pathway = "KEGG: V1/A DOWN"),
    tibble(gene = genes_kegg_v2v1_up$genes, pathway = "KEGG: V2/V1 UP"),
    tibble(gene = genes_kegg_v2v1_down$genes, pathway = "KEGG: V2/V1 DOWN")
  ) %>%
    dplyr::filter(gene != "") %>%
    dplyr::distinct(gene, .keep_all = TRUE)

  genes_raw <- unique(pathway_anno$gene)
  message("Heatmap: ", length(genes_raw), " unique genes from ORA")

  # Alle Gene als SYMBOL behandeln (readable=TRUE in enrichGO) und zu ENSEMBL mappen
  sym_to_ens_map <- NULL
  if (length(genes_raw) > 0) {
    sym_to_ens_map <- suppressMessages(AnnotationDbi::select(
      org.Hs.eg.db,
      keys = unique(genes_raw),
      columns = c("ENSEMBL"),
      keytype = "SYMBOL"
    )) %>%
      dplyr::filter(!is.na(ENSEMBL)) %>%
      dplyr::distinct(SYMBOL, .keep_all = TRUE)

    message("Heatmap: ", nrow(sym_to_ens_map), " genes mapped to ENSEMBL")
  }

  # Finde welche gemappten ENSEMBL IDs in der Matrix vorkommen
  if (!is.null(sym_to_ens_map) && nrow(sym_to_ens_map) > 0) {
    # Match gegen clean rownames (ohne Version)
    genes_in_matrix <- sym_to_ens_map %>%
      dplyr::filter(ENSEMBL %in% trans_rownames_clean)

    message("Heatmap: ", nrow(genes_in_matrix), " genes found in expression matrix")

    if (nrow(genes_in_matrix) >= 5) {
      # Finde die originalen Rownames (mit Version) f√ºr diese Gene
      idx_match <- match(genes_in_matrix$ENSEMBL, trans_rownames_clean)
      genes_present <- rownames(trans_mat)[idx_match]

      # Sample-Sortierung: A -> V1 -> V2
      meta2 <- meta
      meta2$timepoint <- factor(as.character(meta2$timepoint), levels = c("A", "V1", "V2"))
      ord <- order(meta2$timepoint, meta2$pid)

      trans_mat_ord <- trans_mat[, ord, drop = FALSE]

      # Spalten-Annotation
      anno_col <- data.frame(
        timepoint = meta2$timepoint[ord],
        row.names = colnames(trans_mat_ord)
      )

      # Zeilen-Annotation (Pathway) - √ºber SYMBOL joinen
      anno_row_df <- genes_in_matrix %>%
        dplyr::left_join(pathway_anno, by = c("SYMBOL" = "gene")) %>%
        dplyr::mutate(pathway = ifelse(is.na(pathway), "Other", pathway))

      anno_row <- data.frame(
        Pathway = anno_row_df$pathway,
        row.names = genes_present
      )

      # Matrix subset
      mat_sub <- trans_mat_ord[genes_present, , drop = FALSE]

      # Rownames auf SYMBOL √§ndern (besser lesbar)
      rownames(mat_sub) <- genes_in_matrix$SYMBOL
      rownames(anno_row) <- genes_in_matrix$SYMBOL

      # Farben f√ºr Pathways
      all_pathways <- unique(anno_row$Pathway)
      pathway_colors <- c(
        "GO: V1/A UP" = "#e41a1c",
        "GO: V1/A DOWN" = "#377eb8",
        "GO: V2/V1 UP" = "#ff7f00",
        "GO: V2/V1 DOWN" = "#984ea3",
        "KEGG: V1/A UP" = "#4daf4a",
        "KEGG: V1/A DOWN" = "#f781bf",
        "KEGG: V2/V1 UP" = "#a65628",
        "KEGG: V2/V1 DOWN" = "#999999",
        "Other" = "grey70"
      )

      timepoint_colors <- c("A" = "#66c2a5", "V1" = "#fc8d62", "V2" = "#8da0cb")

      anno_colors <- list(
        timepoint = timepoint_colors,
        Pathway = pathway_colors[all_pathways]
      )

      # pheatmap erstellen
      ph <- pheatmap::pheatmap(
        mat_sub,
        scale = "row",
        annotation_col = anno_col,
        annotation_row = anno_row,
        annotation_colors = anno_colors,
        cluster_cols = FALSE,
        cluster_rows = TRUE,
        show_colnames = FALSE,
        fontsize_row = 7,
        fontsize = 9,
        color = colorRampPalette(c("#4575b4", "white", "#d73027"))(100),
        border_color = NA,
        main = paste0("Top ORA genes (n=", nrow(mat_sub), ", row-scaled VST)"),
        silent = TRUE
      )

      heat_panel <- patchwork::wrap_elements(grid::grid.grabExpr(print(ph)))
      message("Heatmap: Successfully created with ", nrow(mat_sub), " genes")
    } else {
      warning("Heatmap: Only ", nrow(genes_in_matrix), " genes found in matrix (need >= 5)")
    }
  } else {
    warning("Heatmap: No genes could be mapped to ENSEMBL")
  }
}

# Fallback Heatmap
if (is.null(heat_panel)) {
  heat_panel <- ggplot() +
    annotate("text", x = 0.5, y = 0.5, label = "Heatmap\n(insufficient data)",
             size = 5, color = "grey50") +
    theme_void() +
    ggtitle("Gene Expression Heatmap") +
    theme(plot.title = element_text(size = 11, face = "bold", hjust = 0.5))
}

# -----------------------------
# 5) Layout zusammenbauen
# -----------------------------
# GO Block (2x2)
go_row1 <- p_go_v1a_up + p_go_v1a_down
go_row2 <- p_go_v2v1_up + p_go_v2v1_down

# KEGG Block (2x2)
kegg_row1 <- p_kegg_v1a_up + p_kegg_v1a_down
kegg_row2 <- p_kegg_v2v1_up + p_kegg_v2v1_down

# Linke Spalte: GO (2 Zeilen) + KEGG (2 Zeilen) = 4 Zeilen
left_col <- (go_row1 / go_row2 / kegg_row1 / kegg_row2) +
  plot_layout(heights = c(1, 1, 1, 1), guides = "collect") &
  theme(legend.position = "right")

# Gesamtfigur: Links (4 Zeilen Dotplots) | Rechts (Heatmap)
fig <- (left_col | heat_panel) +
  plot_layout(widths = c(2.5, 1)) +
  plot_annotation(
    title = title_main,
    subtitle = subtitle_main,
    tag_levels = "A",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "grey30"),
      plot.tag = element_text(size = 14, face = "bold")
    )
  )

print(fig)

# -----------------------------
# 6) Export
# -----------------------------
out_stem <- paste0("FIG_TAVI_GO_KEGG_HEAT_padj", fmt2(padj_cutoff), "_lfc", fmt2(lfc_min), "_pub")
out_base <- file.path(fig_out_dir, out_stem)

ggsave(paste0(out_base, "_v2.pdf"), fig, width = 20, height = 14, device = cairo_pdf)
ggsave(paste0(out_base, "_v2.png"), fig, width = 20, height = 14, dpi = 300)

message("Saved: ", out_base, "_v2.pdf / _v2.png")

```

```{r}
#| label: fig-tavi-story
#| fig-width: 18
#| fig-height: 16
# ============================================================
# STORY FIGURE: TAVI Immune Trajectory
#
# Die biologische Story:
#   Phase 1 (V1 vs A): Akute Entz√ºndung ‚Üë, Adaptive Immunit√§t ‚Üì
#   Phase 2 (V2 vs V1): Entz√ºndung ‚Üì, Immunit√§t erholt sich ‚Üë
#   Phase 3 (V2 vs A): Weitgehend normalisiert
#
# Layout:
#   A) Timeline-Schematic
#   B) V1 vs A UP - Akute Entz√ºndung
#   C) V1 vs A DOWN - Adaptive Immunit√§t supprimiert
#   D) V2 vs V1 DOWN - Entz√ºndung l√∂st sich auf
#   E) V2 vs V1 UP - Immunit√§t erholt sich
#   F) Heatmap - Schl√ºsselgene √ºber alle Zeitpunkte
# ============================================================

# -----------------------------
# 0) Settings
# -----------------------------
padj_cutoff <- 0.05
lfc_min <- 0.5

go_out_dir <- "../../res/functional/ora_go"
fig_out_dir <- "../../res/figures"
dir.create(fig_out_dir, recursive = TRUE, showWarnings = FALSE)

fmt2 <- function(x) format(x, nsmall = 2)

# -----------------------------
# 1) Timeline Schematic Panel
# -----------------------------
create_timeline <- function() {
  # Daten f√ºr Timeline
  timeline_df <- data.frame(
    x = c(1, 2, 3),
    y = c(0, 0, 0),
    label = c("A\n(Baseline)", "V1\n(Post-TAVI)", "V2\n(3 Monate)"),
    phase = c("Baseline", "Acute", "Recovery")
  )


  # Pfeile zwischen Zeitpunkten
  arrows_df <- data.frame(
    x = c(1.15, 2.15),
    xend = c(1.85, 2.85),
    y = c(0, 0),
    yend = c(0, 0),
    label = c("Akute Phase", "Erholungsphase")
  )

  # Biologische Annotationen
  annot_df <- data.frame(
    x = c(1.5, 2.5),
    y = c(0.4, 0.4),
    label = c("Inflammation ‚Üë\nAdaptive Immunity ‚Üì",
              "Inflammation ‚Üì\nImmunity Recovery ‚Üë"),
    color = c("#e41a1c", "#4daf4a")
  )

  ggplot() +
    # Zeitlinie
    geom_segment(aes(x = 0.5, xend = 3.5, y = 0, yend = 0),
                 linewidth = 1.5, color = "grey40") +
    # Zeitpunkte
    geom_point(data = timeline_df, aes(x = x, y = y),
               size = 12, color = c("#66c2a5", "#fc8d62", "#8da0cb")) +
    geom_text(data = timeline_df, aes(x = x, y = y - 0.25, label = label),
              size = 4, fontface = "bold") +
    # Pfeile
    geom_segment(data = arrows_df,
                 aes(x = x, xend = xend, y = y + 0.12, yend = yend + 0.12),
                 arrow = arrow(length = unit(0.3, "cm"), type = "closed"),
                 linewidth = 1.2, color = "grey50") +
    # Biologische Annotationen
    geom_label(data = annot_df, aes(x = x, y = y, label = label),
               fill = c("#fee0d2", "#d9f0d3"), color = "grey20",
               size = 3.2, fontface = "italic", label.padding = unit(0.4, "lines")) +
    # Styling
    coord_cartesian(xlim = c(0.3, 3.7), ylim = c(-0.5, 0.7)) +
    theme_void() +
    labs(title = "TAVI Immune Trajectory: A ‚Üí V1 ‚Üí V2") +
    theme(
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
      plot.margin = margin(10, 10, 10, 10)
    )
}

timeline_panel <- create_timeline()

# -----------------------------
# 2) Helper: Dotplot aus RDS
# -----------------------------
stem_go <- function(set_label, dir) {
  paste0("GO_BP_", set_label, "_", dir, "_padj", fmt2(padj_cutoff), "_lfc", fmt2(lfc_min))
}

safe_read_rds <- function(path) {
  if (!file.exists(path)) return(NULL)
  obj <- tryCatch(readRDS(path), error = function(e) NULL)
  df <- tryCatch(as.data.frame(obj), error = function(e) NULL)
  if (is.null(df) || nrow(df) == 0) return(NULL)
  obj
}

# Einheitliche Farben f√ºr die Story
color_inflammation <- "#d73027"  # Rot f√ºr Entz√ºndung
color_immunity_down <- "#4575b4" # Blau f√ºr Immunit√§t runter
color_resolution <- "#1a9850"    # Gr√ºn f√ºr Aufl√∂sung
color_recovery <- "#ff7f00"      # Orange f√ºr Erholung

story_dotplot <- function(enrich_obj, title, subtitle = NULL,
                          accent_color = "grey30", n_cat = 8) {

  if (is.null(enrich_obj)) {
    return(
      ggplot() +
        annotate("text", x = 0.5, y = 0.5, label = "No enriched terms",
                 size = 4, color = "grey50") +
        theme_void() +
        ggtitle(title) +
        theme(plot.title = element_text(size = 11, face = "bold", hjust = 0.5))
    )
  }

  df <- as.data.frame(enrich_obj)
  if (nrow(df) == 0) {
    return(
      ggplot() +
        annotate("text", x = 0.5, y = 0.5, label = "No enriched terms",
                 size = 4, color = "grey50") +
        theme_void() +
        ggtitle(title) +
        theme(plot.title = element_text(size = 11, face = "bold", hjust = 0.5))
    )
  }

  df_top <- df %>%
    dplyr::slice_head(n = n_cat) %>%
    dplyr::mutate(
      Description = str_wrap(Description, width = 40),
      Description = factor(Description, levels = rev(Description)),
      GeneRatio_num = sapply(strsplit(GeneRatio, "/"),
                             function(x) as.numeric(x[1]) / as.numeric(x[2]))
    )

  p <- ggplot(df_top, aes(x = GeneRatio_num, y = Description)) +
    geom_segment(aes(x = 0, xend = GeneRatio_num, y = Description, yend = Description),
                 color = "grey80", linewidth = 0.5) +
    geom_point(aes(size = Count), color = accent_color, alpha = 0.8) +
    scale_size_continuous(range = c(3, 10), name = "Gene\nCount") +
    labs(x = "Gene Ratio", y = NULL, title = title, subtitle = subtitle) +
    theme_minimal(base_size = 10) +
    theme(
      plot.title = element_text(size = 12, face = "bold", color = accent_color),
      plot.subtitle = element_text(size = 9, color = "grey40", face = "italic"),
      axis.text.y = element_text(size = 9),
      axis.text.x = element_text(size = 8),
      legend.position = "right",
      legend.key.size = unit(0.4, "cm"),
      panel.grid.major.y = element_blank(),
      panel.grid.minor = element_blank()
    )

  p
}

# -----------------------------
# 3) Lade die 4 Schl√ºssel-Vergleiche
# -----------------------------
# V1 vs A UP - Akute Entz√ºndung
go_v1a_up <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("Wald_V1_vs_A", "up"), ".rds")))

# V1 vs A DOWN - Adaptive Immunit√§t supprimiert
go_v1a_down <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("Wald_V1_vs_A", "down"), ".rds")))

# V2 vs V1 DOWN - Entz√ºndung l√∂st sich auf
go_v2v1_down <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("Wald_V2_vs_V1", "down"), ".rds")))

# V2 vs V1 UP - Immunit√§t erholt sich
go_v2v1_up <- safe_read_rds(file.path(go_out_dir, paste0(stem_go("Wald_V2_vs_V1", "up"), ".rds")))

# Dotplots erstellen
p_v1a_up <- story_dotplot(go_v1a_up,
                          title = "V1 vs A: Upregulated",
                          subtitle = "Acute inflammatory response",
                          accent_color = color_inflammation)

p_v1a_down <- story_dotplot(go_v1a_down,
                            title = "V1 vs A: Downregulated",
                            subtitle = "Adaptive immunity suppressed",
                            accent_color = color_immunity_down)

p_v2v1_down <- story_dotplot(go_v2v1_down,
                             title = "V2 vs V1: Downregulated",
                             subtitle = "Inflammation resolving",
                             accent_color = color_resolution)

p_v2v1_up <- story_dotplot(go_v2v1_up,
                           title = "V2 vs V1: Upregulated",
                           subtitle = "Immune recovery",
                           accent_color = color_recovery)

# -----------------------------
# 4) Heatmap: Schl√ºsselgene √ºber alle Zeitpunkte
# -----------------------------
heat_panel <- NULL

if (exists("trans") && exists("meta")) {
  trans_mat <- SummarizedExperiment::assay(trans)
  trans_rownames_clean <- sub("\\..*$", "", rownames(trans_mat))

  # Gene aus ORA-Ergebnissen extrahieren
  get_genes <- function(enrich_obj, n_terms = 2) {
    if (is.null(enrich_obj)) return(character())
    df <- tryCatch(as.data.frame(enrich_obj), error = function(e) NULL)
    if (is.null(df) || nrow(df) == 0) return(character())
    df_top <- df %>% dplyr::slice_head(n = min(n_terms, nrow(df)))
    genes <- unlist(strsplit(df_top$geneID, "/", fixed = TRUE))
    unique(genes[!is.na(genes) & genes != ""])
  }

  # Gene aus allen 4 Vergleichen
  genes_inflam <- get_genes(go_v1a_up, 2)
  genes_immun_down <- get_genes(go_v1a_down, 2)
  genes_resolve <- get_genes(go_v2v1_down, 2)
  genes_recovery <- get_genes(go_v2v1_up, 2)

  # Pathway-Annotation
  pathway_anno <- dplyr::bind_rows(
    tibble(gene = genes_inflam, pathway = "Inflammation (V1‚Üë)"),
    tibble(gene = genes_immun_down, pathway = "Immunity (V1‚Üì)"),
    tibble(gene = genes_resolve, pathway = "Resolution (V2‚Üì)"),
    tibble(gene = genes_recovery, pathway = "Recovery (V2‚Üë)")
  ) %>%
    dplyr::filter(gene != "") %>%
    dplyr::distinct(gene, .keep_all = TRUE)

  genes_raw <- unique(pathway_anno$gene)

  # SYMBOL -> ENSEMBL Mapping
  if (length(genes_raw) > 0) {
    sym_to_ens <- suppressMessages(AnnotationDbi::select(
      org.Hs.eg.db,
      keys = unique(genes_raw),
      columns = c("ENSEMBL"),
      keytype = "SYMBOL"
    )) %>%
      dplyr::filter(!is.na(ENSEMBL)) %>%
      dplyr::distinct(SYMBOL, .keep_all = TRUE)

    genes_in_matrix <- sym_to_ens %>%
      dplyr::filter(ENSEMBL %in% trans_rownames_clean)

    if (nrow(genes_in_matrix) >= 10) {
      idx_match <- match(genes_in_matrix$ENSEMBL, trans_rownames_clean)
      genes_present <- rownames(trans_mat)[idx_match]

      # Sample-Sortierung
      meta2 <- meta
      meta2$timepoint <- factor(as.character(meta2$timepoint), levels = c("A", "V1", "V2"))
      ord <- order(meta2$timepoint, meta2$pid)

      trans_mat_ord <- trans_mat[, ord, drop = FALSE]

      # Annotations
      anno_col <- data.frame(
        Timepoint = meta2$timepoint[ord],
        row.names = colnames(trans_mat_ord)
      )

      anno_row_df <- genes_in_matrix %>%
        dplyr::left_join(pathway_anno, by = c("SYMBOL" = "gene")) %>%
        dplyr::mutate(pathway = ifelse(is.na(pathway), "Other", pathway))

      anno_row <- data.frame(
        Phase = anno_row_df$pathway,
        row.names = genes_present
      )

      mat_sub <- trans_mat_ord[genes_present, , drop = FALSE]
      rownames(mat_sub) <- genes_in_matrix$SYMBOL
      rownames(anno_row) <- genes_in_matrix$SYMBOL

      # Farben
      phase_colors <- c(
        "Inflammation (V1‚Üë)" = color_inflammation,
        "Immunity (V1‚Üì)" = color_immunity_down,
        "Resolution (V2‚Üì)" = color_resolution,
        "Recovery (V2‚Üë)" = color_recovery,
        "Other" = "grey70"
      )

      timepoint_colors <- c("A" = "#66c2a5", "V1" = "#fc8d62", "V2" = "#8da0cb")

      anno_colors <- list(
        Timepoint = timepoint_colors,
        Phase = phase_colors[unique(anno_row$Phase)]
      )

      # Heatmap
      ph <- pheatmap::pheatmap(
        mat_sub,
        scale = "row",
        annotation_col = anno_col,
        annotation_row = anno_row,
        annotation_colors = anno_colors,
        cluster_cols = FALSE,
        cluster_rows = TRUE,
        show_colnames = FALSE,
        fontsize_row = 7,
        fontsize = 9,
        color = colorRampPalette(c("#2166ac", "#f7f7f7", "#b2182b"))(100),
        border_color = NA,
        main = paste0("Key genes across timepoints (n=", nrow(mat_sub), ")"),
        silent = TRUE
      )

      heat_panel <- patchwork::wrap_elements(grid::grid.grabExpr(print(ph)))
    }
  }
}

# Fallback
if (is.null(heat_panel)) {
  heat_panel <- ggplot() +
    annotate("text", x = 0.5, y = 0.5, label = "Heatmap\n(insufficient data)",
             size = 5, color = "grey50") +
    theme_void()
}

# -----------------------------
# 5) Layout zusammenbauen
# -----------------------------
# Obere Reihe: Timeline
# Mittlere Reihe: Phase 1 (V1 vs A)
# Untere Reihe: Phase 2 (V2 vs V1)
# Rechts: Heatmap

# Phase 1 Block
phase1_label <- ggplot() +

  annotate("text", x = 0.5, y = 0.5,
           label = "PHASE 1: Acute Response",
           size = 5, fontface = "bold", color = "grey30") +
  theme_void()

phase1_block <- (p_v1a_up | p_v1a_down) +
  plot_layout(guides = "collect")

# Phase 2 Block
phase2_label <- ggplot() +
  annotate("text", x = 0.5, y = 0.5,
           label = "PHASE 2: Recovery (3 months)",
           size = 5, fontface = "bold", color = "grey30") +
  theme_void()

phase2_block <- (p_v2v1_down | p_v2v1_up) +
  plot_layout(guides = "collect")

# Linke Spalte
left_col <- (timeline_panel / phase1_label / phase1_block / phase2_label / phase2_block) +
  plot_layout(heights = c(1.2, 0.2, 2, 0.2, 2))

# Gesamtfigur
fig_story <- (left_col | heat_panel) +
  plot_layout(widths = c(2.5, 1)) +
  plot_annotation(
    title = "Transcriptomic Response to TAVI: Biphasic Immune Modulation",
    subtitle = paste0("GO Biological Process enrichment (padj < ", padj_cutoff,
                      ", |log2FC| ‚â• ", lfc_min, ") | RNA-seq from peripheral blood"),
    tag_levels = "A",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold"),
      plot.subtitle = element_text(size = 11, color = "grey40"),
      plot.tag = element_text(size = 14, face = "bold")
    )
  )

print(fig_story)

# -----------------------------
# 6) Export
# -----------------------------
out_base <- file.path(fig_out_dir, "FIG_TAVI_immune_trajectory_story")

ggsave(paste0(out_base, ".pdf"), fig_story, width = 18, height = 16, device = cairo_pdf)
ggsave(paste0(out_base, ".png"), fig_story, width = 18, height = 16, dpi = 300)

message("Saved: ", out_base, ".pdf / .png")

```
